### YamlMime:UniversalReference
api_name: []
items:
- children:
  - cntk.ops.abs
  - cntk.ops.alias
  - cntk.ops.argmax
  - cntk.ops.argmin
  - cntk.ops.as_block
  - cntk.ops.as_composite
  - cntk.ops.assign
  - cntk.ops.associative_multi_arg
  - cntk.ops.batch_normalization
  - cntk.ops.ceil
  - cntk.ops.clip
  - cntk.ops.combine
  - cntk.ops.constant
  - cntk.ops.convolution
  - cntk.ops.convolution_transpose
  - cntk.ops.cos
  - cntk.ops.cosh
  - cntk.ops.dropout
  - cntk.ops.element_divide
  - cntk.ops.element_max
  - cntk.ops.element_min
  - cntk.ops.element_select
  - cntk.ops.element_times
  - cntk.ops.elu
  - cntk.ops.equal
  - cntk.ops.exp
  - cntk.ops.floor
  - cntk.ops.forward_backward
  - cntk.ops.gather
  - cntk.ops.greater
  - cntk.ops.greater_equal
  - cntk.ops.hardmax
  - cntk.ops.input
  - cntk.ops.input_variable
  - cntk.ops.labels_to_graph
  - cntk.ops.leaky_relu
  - cntk.ops.less
  - cntk.ops.less_equal
  - cntk.ops.log
  - cntk.ops.log_add_exp
  - cntk.ops.minus
  - cntk.ops.negate
  - cntk.ops.not_equal
  - cntk.ops.one_hot
  - cntk.ops.optimized_rnnstack
  - cntk.ops.output_variable
  - cntk.ops.param_relu
  - cntk.ops.parameter
  - cntk.ops.per_dim_mean_variance_normalize
  - cntk.ops.placeholder
  - cntk.ops.plus
  - cntk.ops.pooling
  - cntk.ops.pow
  - cntk.ops.random_sample
  - cntk.ops.random_sample_inclusion_frequency
  - cntk.ops.reciprocal
  - cntk.ops.reconcile_dynamic_axes
  - cntk.ops.reduce_log_sum_exp
  - cntk.ops.reduce_max
  - cntk.ops.reduce_mean
  - cntk.ops.reduce_min
  - cntk.ops.reduce_prod
  - cntk.ops.reduce_sum
  - cntk.ops.relu
  - cntk.ops.reshape
  - cntk.ops.roipooling
  - cntk.ops.round
  - cntk.ops.selu
  - cntk.ops.sigmoid
  - cntk.ops.sin
  - cntk.ops.sinh
  - cntk.ops.slice
  - cntk.ops.softmax
  - cntk.ops.softplus
  - cntk.ops.splice
  - cntk.ops.sqrt
  - cntk.ops.square
  - cntk.ops.stop_gradient
  - cntk.ops.swapaxes
  - cntk.ops.tanh
  - cntk.ops.times
  - cntk.ops.times_transpose
  - cntk.ops.to_batch
  - cntk.ops.to_sequence
  - cntk.ops.to_sequence_like
  - cntk.ops.transpose
  - cntk.ops.unpack_batch
  - cntk.ops.unpooling
  - cntk.ops.functions
  - cntk.ops.sequence
  fullName: cntk.ops
  langs:
  - python
  module: cntk.ops
  name: ops
  source:
    id: ops
    path: bindings/python/cntk\ops\__init__.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\ops\__init__.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 0
  summary: 'CNTK core operators. Calling these operators creates nodes in the CNTK
    computational graph.

    '
  type: package
  uid: cntk.ops
- example:
  - '

    ```


    >>> C.abs([-1, 1, -2, 3]).eval()

    array([ 1.,  1.,  2.,  3.], dtype=float32)

    ```

    '
  fullName: cntk.ops.abs
  langs:
  - python
  module: cntk.ops
  name: abs
  source:
    id: abs
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 1690
  summary: 'Computes the element-wise absolute of `x`:


    '
  syntax:
    content: abs(x, name='')
    parameters:
    - description: 'numpy array or any @cntk.ops.functions.Function that outputs a
        tensor

        '
      id: x
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.abs
- fullName: cntk.ops.alias
  langs:
  - python
  module: cntk.ops
  name: alias
  source:
    id: alias
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 123
  summary: "   Create a new Function instance which just aliases the specified 'x'\
    \ Function/Variable\n   such that the 'Output' of the new 'Function' is same as\
    \ the 'Output' of the specified\n   'x' Function/Variable, and has the newly specified\
    \ name.\n   The purpose of this operator is to create a new distinct reference\
    \ to a symbolic\n   computation which is different from the original Function/Variable\
    \ that it aliases and can\n   be used for e.g. to substitute a specific instance\
    \ of the aliased Function/Variable in the\n   computation graph instead of substituting\
    \ all usages of the aliased Function/Variable.\n"
  syntax:
    content: alias(x, name='')
    parameters:
    - description: 'The Function/Variable to alias

        '
      id: operand
    - description: 'the name of the Alias Function in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.alias
- example:
  - "\n```\n\n>>> # create 3x2 matrix in a sequence of length 1 in a batch of one\
    \ sample\n>>> data = [[10, 20],[30, 40],[50, 60]]\n```\n\n\n```\n\n>>> C.argmax(data,\
    \ 0).eval()\narray([[ 2.,  2.]], dtype=float32)\n```\n\n\n```\n\n>>> C.argmax(data,\
    \ 1).eval()\narray([[ 1.],\n       [ 1.],\n       [ 1.]], dtype=float32)\n```\n"
  fullName: cntk.ops.argmax
  langs:
  - python
  module: cntk.ops
  name: argmax
  source:
    id: argmax
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 2482
  summary: 'Computes the argmax of the input tensor''s elements across the specified
    axis.

    If no axis is specified, it will return the flatten index of the largest element

    in tensor x.

    '
  syntax:
    content: argmax(x, axis=None, name='')
    parameters:
    - description: 'any @cntk.ops.functions.Function that outputs a tensor.

        '
      id: x
      type:
      - 'numpy.array or @cntk.ops.functions.Function

        '
    - description: 'axis along which the reduction will be performed

        '
      id: axis
      type:
      - 'int or @cntk.axis.Axis

        '
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, default to ''
    return:
      description: 'An instance of @cntk.ops.functions.Function

        '
      type:
      - cntk.ops.functions.Function
  type: function
  uid: cntk.ops.argmax
- example:
  - "\n```\n\n>>> # create 3x2 matrix in a sequence of length 1 in a batch of one\
    \ sample\n>>> data = [[10, 30],[40, 20],[60, 50]]\n```\n\n\n```\n\n>>> C.argmin(data,\
    \ 0).eval()\narray([[ 0.,  1.]], dtype=float32)\n```\n\n\n```\n\n>>> C.argmin(data,\
    \ 1).eval()\narray([[ 0.],\n       [ 1.],\n       [ 1.]], dtype=float32)\n```\n"
  fullName: cntk.ops.argmin
  langs:
  - python
  module: cntk.ops
  name: argmin
  source:
    id: argmin
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 2515
  summary: 'Computes the argmin of the input tensor''s elements across the specified
    axis.

    If no axis is specified, it will return the flatten index of the smallest element

    in tensor x.

    '
  syntax:
    content: argmin(x, axis=None, name='')
    parameters:
    - description: 'any @cntk.ops.functions.Function that outputs a tensor.

        '
      id: x
      type:
      - 'numpy.array or @cntk.ops.functions.Function

        '
    - description: 'axis along which the reduction will be performed

        '
      id: axis
      type:
      - 'int or @cntk.axis.Axis

        '
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, default to ''
    return:
      description: 'An instance of @cntk.ops.functions.Function

        '
      type:
      - cntk.ops.functions.Function
  type: function
  uid: cntk.ops.argmin
- fullName: cntk.ops.as_block
  langs:
  - python
  module: cntk.ops
  name: as_block
  source:
    id: as_block
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 80
  summary: "   Create a new block Function instance which just encapsulates the specified\
    \ composite Function\n   to create a new Function that appears to be a primitive.\
    \ All the arguments of the composite\n   being encapsulated must be Placeholder\
    \ variables.\n   The purpose of block Functions is to enable creation of hierarchical\
    \ Function graphs\n   where details of implementing certain building block operations\
    \ can be encapsulated away\n   such that the actual structure of the block's implementation\
    \ is not inlined into\n   the parent graph where the block is used, and instead\
    \ the block just appears as an opaque\n   primitive. Users still have the ability\
    \ to peek at the underlying Function graph that implements\n   the actual block\
    \ Function.\n"
  syntax:
    content: as_block(composite, block_arguments_map, block_op_name, block_instance_name='')
    parameters:
    - description: 'The composite Function that the block encapsulates

        '
      id: composite
    - description: 'A list of tuples, mapping from block''s underlying composite''s
        arguments to

        actual variables they are connected to

        '
      id: block_arguments_map
    - description: 'Name of the op that the block represents

        '
      id: block_op_name
    - description: 'the name of the block Function in the network

        '
      id: block_instance_name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.as_block
- fullName: cntk.ops.as_composite
  langs:
  - python
  module: cntk.ops
  name: as_composite
  source:
    id: as_composite
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 106
  summary: "   Creates a composite Function that has the specified root_function as\
    \ its root.\n   The composite denotes a higher-level Function encapsulating the\
    \ entire graph\n   of Functions underlying the specified rootFunction.\n"
  syntax:
    content: as_composite(root_function, name='')
    parameters:
    - description: 'Root Function, the graph underlying which, the newly created composite
        encapsulates

        '
      id: root_function
    - description: 'the name of the Alias Function in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.as_composite
- example:
  - "\n```\n\n>>> dest = C.constant(shape=(3,4))\n>>> data = C.parameter(shape=(3,4),\
    \ init=2)\n>>> C.assign(dest,data).eval()\narray([[ 2.,  2.,  2.,  2.],\n    \
    \   [ 2.,  2.,  2.,  2.],\n       [ 2.,  2.,  2.,  2.]], dtype=float32)\n>>> dest.asarray()\n\
    array([[ 2.,  2.,  2.,  2.],\n       [ 2.,  2.,  2.,  2.],\n       [ 2.,  2.,\
    \  2.,  2.]], dtype=float32)\n```\n\n\n```\n\n>>> dest = C.parameter(shape=(3,4),\
    \ init=0)\n>>> a = C.assign(dest, data)\n>>> y = dest + data\n>>> result = C.combine([y,\
    \ a]).eval()\n>>> result[y.output]\narray([[ 2.,  2.,  2.,  2.],\n       [ 2.,\
    \  2.,  2.,  2.],\n       [ 2.,  2.,  2.,  2.]], dtype=float32)\n>>> dest.asarray()\n\
    array([[ 2.,  2.,  2.,  2.],\n       [ 2.,  2.,  2.,  2.],\n       [ 2.,  2.,\
    \  2.,  2.]], dtype=float32)\n>>> result = C.combine([y, a]).eval()\n>>> result[y.output]\n\
    array([[ 4.,  4.,  4.,  4.],\n       [ 4.,  4.,  4.,  4.],\n       [ 4.,  4.,\
    \  4.,  4.]], dtype=float32)\n>>> dest.asarray()\narray([[ 2.,  2.,  2.,  2.],\n\
    \       [ 2.,  2.,  2.,  2.],\n       [ 2.,  2.,  2.,  2.]], dtype=float32)\n\
    ```\n"
  fullName: cntk.ops.assign
  langs:
  - python
  module: cntk.ops
  name: assign
  source:
    id: assign
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 2994
  summary: 'Assign the value in input to ref and return the new value, ref need to
    be the same layout as input.

    Both ref and input can''t have dynamic axis and broadcast isn''t supported for
    the assign operator.

    During forward pass, ref will get the new value after the forward or backward
    pass finish, so that

    any part of the graph that depend on ref will get the old value. To get the new
    value, use the one

    returned by the assign node. The reason for that is to make `assign` have a deterministic
    behavior.


    If not computing gradients, the ref will be assigned the new value after the forward
    pass over the

    entire Function graph is complete; i.e. all uses of ref in the forward pass will
    use the original

    (pre-assignment) value of ref.


    If computing gradients (training mode), the assignment to ref will happen after
    completing both

    the forward and backward passes over the entire Function graph.


    The ref must be a Parameter or Constant. If the same ref is used in multiple assign
    operations,

    then the order in which the assignment happens is non-deterministic and the final
    value can be

    either of the assignments unless an order is established using a data dependence
    between the

    assignments.

    '
  syntax:
    content: assign(ref, input, name='')
    parameters:
    - description: 'class: *~cntk.variables.Constant* or *~cntk.variables.Parameter*.

        '
      id: ref
    - description: 'class:*~cntk.ops.functions.Function* that outputs a tensor

        '
      id: input
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.assign
- example:
  - '

    ```


    >>> C.plus([1, 2, 3], [4, 5, 6]).eval()

    array([ 5.,  7.,  9.], dtype=float32)

    ```



    ```


    >>> C.element_times([5., 10., 15., 30.], [2.]).eval()

    array([ 10.,  20.,  30.,  60.], dtype=float32)

    ```



    ```


    >>> C.plus([-5, -4, -3, -2, -1], [10], [3, 2, 3, 2, 3], [-13], [+42], ''multi_arg_example'').eval()

    array([ 37.,  37.,  39.,  39.,  41.], dtype=float32)

    ```



    ```


    >>> C.element_times([5., 10., 15., 30.], [2.], [1., 2., 1., 2.]).eval()

    array([  10.,   40.,   30.,  120.], dtype=float32)

    ```



    ```


    >>> a = np.arange(3,dtype=np.float32)

    >>> np.exp(C.log_add_exp(np.log(1+a), np.log(1+a*a)).eval())

    array([ 2.,  4.,  8.], dtype=float32)

    ```

    '
  fullName: cntk.ops.associative_multi_arg
  langs:
  - python
  module: cntk.ops
  name: associative_multi_arg
  source:
    id: associative_multi_arg
    path: bindings/python/cntk\ops\__init__.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\ops\__init__.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 671
  summary: 'The output of this operation is the result of an operation (*plus*, *log_add_exp*,
    *element_times*, *element_max*, *element_min*)

    of two or more input tensors. Broadcasting is supported.

    '
  syntax:
    content: associative_multi_arg(f)
    parameters:
    - description: 'left side tensor

        '
      id: left
    - &id001
      description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    - *id001
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.associative_multi_arg
- fullName: cntk.ops.batch_normalization
  langs:
  - python
  module: cntk.ops
  name: batch_normalization
  source:
    id: batch_normalization
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 460
  summary: 'Normalizes layer outputs for every minibatch for each output (feature)
    independently

    and applies affine transformation to preserve representation of the layer.

    '
  syntax:
    content: batch_normalization(operand, scale, bias, running_mean, running_inv_std,
      spatial, normalization_time_constant=5000, blend_time_constant=0, epsilon=1e-05,
      use_cudnn_engine=False, name='', running_count=None)
    parameters:
    - description: 'input of the batch normalization operation

        '
      id: operand
    - description: 'parameter tensor that holds the learned componentwise-scaling
        factors

        '
      id: scale
    - description: 'parameter tensor that holds the learned bias. `scale` and `bias`
        must have the same

        dimensions which must be equal to the input dimensions in case of `spatial`
        = False or

        number of output convolution feature maps in case of `spatial` = True

        '
      id: bias
    - description: 'running mean which is used during evaluation phase and might be
        used during

        training as well. You must pass a constant tensor with initial value 0 and
        the same dimensions

        as `scale` and `bias`

        '
      id: running_mean
    - description: 'running variance. Represented as `running_mean`

        '
      id: running_inv_std
    - description: 'Denotes the total number of samples that have been used so far
        to compute

        the `running_mean` and `running_inv_std` parameters. You must pass a scalar
        (either rank-0 `constant(val)`).

        '
      id: running_count
    - description: 'flag that indicates whether to compute mean/var for each feature
        in a minibatch

        independently or, in case of convolutional layers, per future map

        '
      id: spatial
      type:
      - bool
    - description: 'time constant for computing running average of

        mean and variance as a low-pass filtered version of the batch statistics.

        '
      id: normalization_time_constant
      type:
      - float, default 5000
    - description: 'constant for smoothing batch estimates with the running

        statistics

        '
      id: blend_time_constant
      type:
      - float, default 0
    - description: 'conditioner constant added to the variance when computing the
        inverse standard deviation

        '
      id: epsilon
    - description: ''
      id: use_cudnn_engine
      type:
      - bool, default True
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.batch_normalization
- example:
  - "\n```\n\n>>> C.ceil([0.2, 1.3, 4., 5.5, 0.0]).eval()\narray([ 1.,  2.,  4., \
    \ 6.,  0.], dtype=float32)\n```\n\n\n```\n\n>>> C.ceil([[0.6, 3.3], [1.9, 5.6]]).eval()\n\
    array([[ 1.,  4.],\n       [ 2.,  6.]], dtype=float32)\n```\n"
  fullName: cntk.ops.ceil
  langs:
  - python
  module: cntk.ops
  name: ceil
  source:
    id: ceil
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 1132
  summary: 'The output of this operation is the element wise value rounded to the
    smallest

    integer greater than or equal to the input.

    '
  syntax:
    content: ceil(arg, name='')
    parameters:
    - description: 'input tensor

        '
      id: arg
    - description: 'the name of the Function instance in the network (optional)

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.ceil
- example:
  - '

    ```


    >>> C.clip([1., 2.1, 3.0, 4.1], 2., 4.).eval()

    array([ 2. ,  2.1,  3. ,  4. ], dtype=float32)

    ```



    ```


    >>> C.clip([-10., -5., 0., 5., 10.], [-5., -4., 0., 3., 5.], [5., 4., 1., 4.,
    9.]).eval()

    array([-5., -4.,  0.,  4.,  9.], dtype=float32)

    ```

    '
  fullName: cntk.ops.clip
  langs:
  - python
  module: cntk.ops
  name: clip
  source:
    id: clip
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 1196
  summary: 'Computes a tensor with all of its values clipped to fall

    between `min_value` and `max_value`, i.e.

    `min(max(x, min_value), max_value)`.


    The output tensor has the same shape as `x`.

    '
  syntax:
    content: clip(x, min_value, max_value, name='')
    parameters:
    - description: 'tensor to be clipped

        '
      id: x
    - description: 'a scalar or a tensor which represents the minimum value to clip
        element

        values to

        '
      id: min_value
      type:
      - float
    - description: 'a scalar or a tensor which represents the maximum value to clip
        element

        values to

        '
      id: max_value
      type:
      - float
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.clip
- example:
  - "\n```\n\n>>> in1 = C.input_variable((4,))\n>>> in2 = C.input_variable((4,))\n\
    ```\n\n\n```\n\n>>> in1_data = np.asarray([[1., 2., 3., 4.]], np.float32)\n>>>\
    \ in2_data = np.asarray([[0., 5., -3., 2.]], np.float32)\n```\n\n\n```\n\n>>>\
    \ plus_operation = in1 + in2\n>>> minus_operation = in1 - in2\n```\n\n\n```\n\n\
    >>> forward = C.combine([plus_operation, minus_operation]).eval({in1: in1_data,\
    \ in2: in2_data})\n>>> len(forward)\n2\n>>> list(forward.values()) # doctest:\
    \ +SKIP\n[array([[[ 1., -3.,  6.,  2.]]], dtype=float32),\n array([[[ 1.,  7.,\
    \  0.,  6.]]], dtype=float32)]\n>>> x = C.input_variable((4,))\n>>> _ = C.combine(x,\
    \ x)\n>>> _ = C.combine([x, x])\n>>> _ = C.combine((x, x))\n>>> _ = C.combine(C.combine(x,\
    \ x), x)\n```\n"
  fullName: cntk.ops.combine
  langs:
  - python
  module: cntk.ops
  name: combine
  source:
    id: combine
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 26
  summary: "   Create a new Function instance which just combines the outputs of the\
    \ specified list of\n   'operands' Functions such that the 'Outputs' of the new\
    \ 'Function' are union of the\n   'Outputs' of each of the specified 'operands'\
    \ Functions. E.g., when creating a classification\n   model, typically the CrossEntropy\
    \ loss Function and the ClassificationError Function comprise\n   the two roots\
    \ of the computation graph which can be combined to create a single Function\n\
    \   with 2 outputs; viz. CrossEntropy loss and ClassificationError output.\n"
  syntax:
    content: combine(*operands, **kw_name)
    parameters:
    - description: 'list of functions or their variables to combine

        '
      id: operands
      type:
      - list
    - description: 'the name of the Combine Function in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.combine
- example:
  - "\n```\n\n>>> constant_data = C.constant([[1., 2.], [3., 4.], [5., 6.]])\n>>>\
    \ constant_data.value\narray([[ 1.,  2.],\n       [ 3.,  4.],\n       [ 5.,  6.]],\
    \ dtype=float32)\n```\n"
  fullName: cntk.ops.constant
  langs:
  - python
  module: cntk.ops
  name: constant
  source:
    id: constant
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 2925
  summary: 'It creates a constant tensor initialized from a numpy array

    '
  syntax:
    content: constant(value=None, shape=None, dtype=None, device=None, name='')
    parameters:
    - description: 'a scalar initial value that would be replicated for

        every element in the tensor or NumPy array.

        If `None`, the tensor will be initialized uniformly random.

        '
      id: value
      type:
      - scalar or NumPy array, optional
    - description: 'the shape of the input tensor. If not provided, it will

        be inferred from `value`.

        '
      id: shape
      type:
      - tuple or int, optional
    - description: 'data type of the constant. If a NumPy array and `dtype`,

        are given, then data will be converted if needed. If none given, it will default
        to `np.float32`.

        '
      id: dtype
      type:
      - optional
    - description: 'instance of DeviceDescriptor

        '
      id: device
      type:
      - cntk.device.DeviceDescriptor
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.variables.Constant

        '
  type: function
  uid: cntk.ops.constant
- example:
  - "\n```\n\n>>> img = np.reshape(np.arange(25.0, dtype = np.float32), (1, 5, 5))\n\
    >>> x = C.input_variable(img.shape)\n>>> filter = np.reshape(np.array([2, -1,\
    \ -1, 2], dtype = np.float32), (1, 2, 2))\n>>> kernel = C.constant(value = filter)\n\
    >>> np.round(C.convolution(kernel, x, auto_padding = [False]).eval({x: [img]}),5)\n\
    array([[[[  6.,   8.,  10.,  12.],\n          [ 16.,  18.,  20.,  22.],\n    \
    \      [ 26.,  28.,  30.,  32.],\n          [ 36.,  38.,  40.,  42.]]]], dtype=float32)\n\
    ```\n"
  fullName: cntk.ops.convolution
  langs:
  - python
  module: cntk.ops
  name: convolution
  source:
    id: convolution
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 217
  summary: "Computes the convolution of `convolution_map` (typically a tensor of learnable\
    \ parameters) with\n`operand` (commonly an image or output of a previous convolution/pooling\
    \ operation).\nThis operation is used in image and language processing applications.\
    \ It supports arbitrary\ndimensions, strides, sharing, and padding.\n\nThis function\
    \ operates on input tensors with dimensions . This can be understood as a rank-n\n\
    object, where each entry consists of a -dimensional vector. For example, an RGB\
    \ image would have dimensions\n, i.e. a -sized structure, where each entry (pixel)\
    \ consists of a 3-tuple.\n\n*convolution* convolves the input `operand` with a\
    \  rank tensor of (typically learnable) filters called\n`convolution_map` of shape\
    \  (typically ).\nThe first dimension, , is the nunber of convolution filters\
    \ (i.e. the number of\nchannels in the output). The second dimension, , must match\
    \ the number of channels in the input.\nThe last n dimensions are the spatial\
    \ extent of the filter. I.e. for each output position, a vector of\ndimension\
    \  is computed. Hence, the total number of filter parameters is \n"
  syntax:
    content: convolution(convolution_map, operand, strides=(1,), sharing=[True], auto_padding=[True],
      max_temp_mem_size_in_samples=0, name='')
    parameters:
    - description: 'convolution filter weights, stored as a tensor of dimensions ,

        where  must be the kernel dimensions (spatial extent of the filter).

        '
      id: convolution_map
    - description: 'convolution input. A tensor with dimensions .

        '
      id: operand
    - description: 'stride dimensions. If strides[i] > 1 then only pixel positions
        that are multiples of strides[i] are computed.

        For example, a stride of 2 will lead to a halving of that dimension. The first
        stride dimension that lines up with the number

        of input channels can be set to any non-zero value.

        '
      id: strides
      type:
      - tuple, optional
    - description: 'sharing flags for each input dimension

        '
      id: sharing
      type:
      - bool
    - description: 'flags for each input dimension whether it should be padded automatically
        (that is,

        symmetrically) or not padded at all. Padding means that the convolution kernel
        is applied to all pixel positions, where all

        pixels outside the area are assumed zero ("padded with zeroes"). Without padding,
        the kernels are only shifted over

        positions where all inputs to the kernel still fall inside the area. In this
        case, the output dimension will be less than

        the input dimension. The last value that lines up with the number of input
        channels must be false.

        '
      id: auto_padding
      type:
      - bool
    - description: 'maximum amount of auxiliary memory (in samples) that should be
        reserved to perform convolution

        operations. Some convolution engines (e.g. cuDNN and GEMM-based engines) can
        benefit from using workspace as it may improve

        performance. However, sometimes this may lead to higher memory utilization.
        Default is 0 which means the same as the input

        samples.

        '
      id: max_temp_mem_size_in_samples
      type:
      - int
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.convolution
- example:
  - "\n```\n\n>>> img = np.reshape(np.arange(9.0, dtype = np.float32), (1, 3, 3))\n\
    >>> x = C.input_variable(img.shape)\n>>> filter = np.reshape(np.array([2, -1,\
    \ -1, 2], dtype = np.float32), (1, 2, 2))\n>>> kernel = C.constant(value = filter)\n\
    >>> np.round(C.convolution_transpose(kernel, x, auto_padding = [False]).eval({x:\
    \ [img]}),5)\narray([[[[  0.,   2.,   3.,  -2.],\n          [  6.,   4.,   6.,\
    \  -1.],\n          [  9.,  10.,  12.,   2.],\n          [ -6.,   5.,   6.,  16.]]]],\
    \ dtype=float32)\n```\n"
  fullName: cntk.ops.convolution_transpose
  langs:
  - python
  module: cntk.ops
  name: convolution_transpose
  source:
    id: convolution_transpose
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 276
  summary: "Computes the transposed convolution of `convolution_map` (typically a\
    \ tensor of learnable parameters) with\n`operand` (commonly an image or output\
    \ of a previous convolution/pooling operation).\nThis is also known as `fractionally\
    \ strided convolutional layers`, or, `deconvolution`.\nThis operation is used\
    \ in image and language processing applications. It supports arbitrary\ndimensions,\
    \ strides, sharing, and padding.\n\nThis function operates on input tensors with\
    \ dimensions . This can be understood as a rank-n\nobject, where each entry consists\
    \ of a -dimensional vector. For example, an RGB image would have dimensions\n\
    , i.e. a -sized structure, where each entry (pixel) consists of a 3-tuple.\n\n\
    *convolution_transpose* convolves the input `operand` with a  rank tensor of (typically\
    \ learnable) filters called\n`convolution_map` of shape  (typically ).\nThe first\
    \ dimension, , must match the number of channels in the input. The second dimension,\
    \ , is the number of convolution filters (i.e. the number of\nchannels in the\
    \ output).\nThe last n dimensions are the spatial extent of the filter. I.e. for\
    \ each output position, a vector of\ndimension  is computed. Hence, the total\
    \ number of filter parameters is \n"
  syntax:
    content: convolution_transpose(convolution_map, operand, strides=(1,), sharing=[True],
      auto_padding=[True], output_shape=None, max_temp_mem_size_in_samples=0, name='')
    parameters:
    - description: 'convolution filter weights, stored as a tensor of dimensions ,

        where  must be the kernel dimensions (spatial extent of the filter).

        '
      id: convolution_map
    - description: 'convolution input. A tensor with dimensions .

        '
      id: operand
    - description: 'stride dimensions. If strides[i] > 1 then only pixel positions
        that are multiples of strides[i] are computed.

        For example, a stride of 2 will lead to a halving of that dimension. The first
        stride dimension that lines up with the number

        of input channels can be set to any non-zero value.

        '
      id: strides
      type:
      - tuple, optional
    - description: 'sharing flags for each input dimension

        '
      id: sharing
      type:
      - bool
    - description: 'flags for each input dimension whether it should be padded automatically
        (that is,

        symmetrically) or not padded at all. Padding means that the convolution kernel
        is applied to all pixel positions, where all

        pixels outside the area are assumed zero ("padded with zeroes"). Without padding,
        the kernels are only shifted over

        positions where all inputs to the kernel still fall inside the area. In this
        case, the output dimension will be less than

        the input dimension. The last value that lines up with the number of input
        channels must be false.

        '
      id: auto_padding
      type:
      - bool
    - description: 'user expected output shape after convolution transpose.

        '
      id: output_shape
    - description: 'maximum amount of auxiliary memory (in samples) that should be
        reserved to perform convolution

        operations. Some convolution engines (e.g. cuDNN and GEMM-based engines) can
        benefit from using workspace as it may improve

        performance. However, sometimes this may lead to higher memory utilization.
        Default is 0 which means the same as the input

        samples.

        '
      id: max_temp_mem_size_in_samples
      type:
      - int
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.convolution_transpose
- example:
  - "\n```\n\n>>> np.round(C.cos(np.arccos([[1,0.5],[-0.25,-0.75]])).eval(),5)\narray([[\
    \ 1.  ,  0.5 ],\n       [-0.25, -0.75]], dtype=float32)\n```\n"
  fullName: cntk.ops.cos
  langs:
  - python
  module: cntk.ops
  name: cos
  source:
    id: cos
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 1457
  summary: 'Computes the element-wise cosine of `x`:


    The output tensor has the same shape as `x`.

    '
  syntax:
    content: cos(x, name='')
    parameters:
    - description: 'numpy array or any @cntk.ops.functions.Function that outputs a
        tensor

        '
      id: x
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.cos
- example:
  - "\n```\n\n>>> np.round(C.cosh([[1,0.5],[-0.25,-0.75]]).eval(),5)\narray([[ 1.54308,\
    \  1.12763],\n       [ 1.03141,  1.29468]], dtype=float32)\n```\n"
  fullName: cntk.ops.cosh
  langs:
  - python
  module: cntk.ops
  name: cosh
  source:
    id: cosh
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 1501
  summary: 'Computes the element-wise cosh of `x`:


    The output tensor has the same shape as `x`.

    '
  syntax:
    content: cosh(x, name='')
    parameters:
    - description: 'numpy array or any @cntk.ops.functions.Function that outputs a
        tensor

        '
      id: x
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.cosh
- example:
  - "\n```\n\n>>> data = [[10, 20],[30, 40],[50, 60]]\n>>> C.dropout(data, 0.5).eval()\
    \ # doctest: +SKIP\narray([[  0.,  40.],\n       [  0.,  80.],\n       [  0.,\
    \   0.]], dtype=float32)\n```\n\n\n```\n\n>>> C.dropout(data, 0.75).eval() # doctest:\
    \ +SKIP\narray([[   0.,    0.],\n       [   0.,  160.],\n       [   0.,  240.]],\
    \ dtype=float32)\n```\n"
  fullName: cntk.ops.dropout
  langs:
  - python
  module: cntk.ops
  name: dropout
  source:
    id: dropout
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 2716
  summary: 'Each element of the input is independently set to 0 with probabily `dropout_rate`

    or to 1 / (1 - `dropout_rate`) times its original value (with probability 1-`dropout_rate`).

    Dropout is a good way to reduce overfitting.


    This behavior only happens during training. During inference dropout is a no-op.

    In the paper that introduced dropout it was suggested to scale the weights during
    inference

    In CNTK''s implementation, because the values that are not set to 0 are multiplied

    with (1 / (1 - `dropout_rate`)), this is not necessary.

    '
  syntax:
    content: dropout(x, dropout_rate=0.0, seed=4294967293, name='')
    parameters:
    - description: 'input tensor

        '
      id: x
    - description: 'probability that an element of `x` will be set to zero

        '
      id: dropout_rate
      type:
      - float, [0,1)
    - description: 'random seed.

        '
      id: seed
      type:
      - int
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - 'cntk.ops.str

        , optional'
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.dropout
- example:
  - '

    ```


    >>> C.element_divide([1., 1., 1., 1.], [0.5, 0.25, 0.125, 0.]).eval()

    array([ 2.,  4.,  8.,  0.], dtype=float32)

    ```



    ```


    >>> C.element_divide([5., 10., 15., 30.], [2.]).eval()

    array([  2.5,   5. ,   7.5,  15. ], dtype=float32)

    ```

    '
  fullName: cntk.ops.element_divide
  langs:
  - python
  module: cntk.ops
  name: element_divide
  source:
    id: element_divide
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 883
  summary: 'The output of this operation is the element-wise division of the two input

    tensors. It supports broadcasting.

    '
  syntax:
    content: element_divide(left, right, name='')
    parameters:
    - description: 'left side tensor

        '
      id: left
    - description: 'right side tensor

        '
      id: right
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.element_divide
- fullName: cntk.ops.element_max
  langs:
  - python
  module: cntk.ops
  name: element_max
  source:
    id: element_max
    path: bindings/python/cntk\ops\__init__.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\ops\__init__.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 843
  summary: 'The output of this operation is the element-wise max of the two or more
    input

    tensors. It supports broadcasting.

    '
  syntax:
    content: element_max(left, right, name='')
    parameters:
    - description: 'left side tensor

        '
      id: arg1
    - description: 'right side tensor

        '
      id: arg2
    - &id002
      description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    - *id002
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.element_max
- fullName: cntk.ops.element_min
  langs:
  - python
  module: cntk.ops
  name: element_min
  source:
    id: element_min
    path: bindings/python/cntk\ops\__init__.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\ops\__init__.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 863
  summary: 'The output of this operation is the element-wise min of the two or more
    input

    tensors. It supports broadcasting.

    '
  syntax:
    content: element_min(left, right, name='')
    parameters:
    - description: 'left side tensor

        '
      id: arg1
    - description: 'right side tensor

        '
      id: arg2
    - &id003
      description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    - *id003
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.element_min
- example:
  - '

    ```


    >>> C.element_select([-10, -1, 0, 0.3, 100], [1, 10, 100, 1000, 10000], [ 2, 20,
    200, 2000, 20000]).eval()

    array([     1.,     10.,    200.,   1000.,  10000.], dtype=float32)

    ```

    '
  fullName: cntk.ops.element_select
  langs:
  - python
  module: cntk.ops
  name: element_select
  source:
    id: element_select
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 1754
  summary: 'return either `value_if_true` or `value_if_false` based on the value of
    `flag`.

    If `flag` != 0 `value_if_true` is returned, otherwise `value_if_false`.

    Behaves analogously to numpy.where(...).

    '
  syntax:
    content: element_select(flag, value_if_true, value_if_false, name='')
    parameters:
    - description: 'condition tensor

        '
      id: flag
    - description: 'true branch tensor

        '
      id: value_if_true
    - description: 'false branch tensor

        '
      id: value_if_false
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.element_select
- example:
  - '

    ```


    >>> C.element_times([1., 1., 1., 1.], [0.5, 0.25, 0.125, 0.]).eval()

    array([ 0.5  ,  0.25 ,  0.125,  0.   ], dtype=float32)

    ```



    ```


    >>> C.element_times([5., 10., 15., 30.], [2.]).eval()

    array([ 10.,  20.,  30.,  60.], dtype=float32)

    ```



    ```


    >>> C.element_times([5., 10., 15., 30.], [2.], [1., 2., 1., 2.]).eval()

    array([  10.,   40.,   30.,  120.], dtype=float32)

    ```

    '
  fullName: cntk.ops.element_times
  langs:
  - python
  module: cntk.ops
  name: element_times
  source:
    id: element_times
    path: bindings/python/cntk\ops\__init__.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\ops\__init__.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 810
  summary: 'The output of this operation is the element-wise product of the two or
    more input

    tensors. It supports broadcasting.

    '
  syntax:
    content: element_times(left, right, name='')
    parameters:
    - description: 'left side tensor

        '
      id: arg1
    - description: 'right side tensor

        '
      id: arg2
    - &id004
      description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    - *id004
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.element_times
- example:
  - '

    ```


    >>> C.elu([[-1, -0.5, 0, 1, 2]]).eval()

    array([[-0.632121, -0.393469,  0.      ,  1.      ,  2.      ]], dtype=float32)

    ```

    '
  fullName: cntk.ops.elu
  langs:
  - python
  module: cntk.ops
  name: elu
  source:
    id: elu
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 1252
  summary: 'Exponential linear unit operation. Computes the element-wise exponential
    linear

    of `x`: `max(x, 0)` for `x >= 0` and `x`: `exp(x)-1` otherwise.


    The output tensor has the same shape as `x`.

    '
  syntax:
    content: elu(x, name='')
    parameters:
    - description: 'any @cntk.ops.functions.Function that outputs a tensor.

        '
      id: x
      type:
      - 'numpy.array or @cntk.ops.functions.Function

        '
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, default to ''
    return:
      description: 'An instance of @cntk.ops.functions.Function

        '
      type:
      - cntk.ops.functions.Function
  type: function
  uid: cntk.ops.elu
- example:
  - '

    ```


    >>> C.equal([41., 42., 43.], [42., 42., 42.]).eval()

    array([ 0.,  1.,  0.], dtype=float32)

    ```



    ```


    >>> C.equal([-1,0,1], [1]).eval()

    array([ 0.,  0.,  1.], dtype=float32)

    ```

    '
  fullName: cntk.ops.equal
  langs:
  - python
  module: cntk.ops
  name: equal
  source:
    id: equal
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 536
  summary: 'Elementwise ''equal'' comparison of two tensors. Result is 1 if values
    are equal 0 otherwise.

    '
  syntax:
    content: equal(left, right, name='')
    parameters:
    - description: 'left side tensor

        '
      id: left
    - description: 'right side tensor

        '
      id: right
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.equal
- example:
  - '

    ```


    >>> C.exp([0., 1.]).eval()

    array([ 1.      ,  2.718282], dtype=float32)

    ```

    '
  fullName: cntk.ops.exp
  langs:
  - python
  module: cntk.ops
  name: exp
  source:
    id: exp
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 1596
  summary: 'Computes the element-wise exponential of `x`:


    '
  syntax:
    content: exp(x, name='')
    parameters:
    - description: 'numpy array or any @cntk.ops.functions.Function that outputs a
        tensor

        '
      id: x
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.exp
- example:
  - "\n```\n\n>>> C.floor([0.2, 1.3, 4., 5.5, 0.0]).eval()\narray([ 0.,  1.,  4.,\
    \  5.,  0.], dtype=float32)\n```\n\n\n```\n\n>>> C.floor([[0.6, 3.3], [1.9, 5.6]]).eval()\n\
    array([[ 0.,  3.],\n       [ 1.,  5.]], dtype=float32)\n```\n\n\n```\n\n>>> C.floor([-5.5,\
    \ -4.2, -3., -0.7, 0]).eval()\narray([-6., -5., -3., -1.,  0.], dtype=float32)\n\
    ```\n\n\n```\n\n>>> C.floor([[-0.6, -4.3], [1.9, -3.2]]).eval()\narray([[-1.,\
    \ -5.],\n       [ 1., -4.]], dtype=float32)\n```\n"
  fullName: cntk.ops.floor
  langs:
  - python
  module: cntk.ops
  name: floor
  source:
    id: floor
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 1100
  summary: 'The output of this operation is the element wise value rounded to the
    largest

    integer less than or equal to the input.

    '
  syntax:
    content: floor(arg, name='')
    parameters:
    - description: 'input tensor

        '
      id: arg
    - description: 'the name of the Function instance in the network (optional)

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.floor
- fullName: cntk.ops.forward_backward
  langs:
  - python
  module: cntk.ops
  name: forward_backward
  source:
    id: forward_backward
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 189
  summary: "Criterion node for training methods that rely on forward-backward Viterbi-like\
    \ passes, e.g. Connectionist Temporal Classification (CTC) training\nThe node\
    \ takes as the input the graph of labels, produced by the labels_to_graph operation\
    \ that determines the exact forward/backward procedure.\n.. admonition:: Example\n\
    \n   graph = cntk.labels_to_graph(labels)\n   networkOut = model(features)\n \
    \  fb = C.forward_backward(graph, networkOut, 132)\n"
  syntax:
    content: forward_backward(graph, features, blankTokenId, delayConstraint=-1, name='')
    parameters:
    - description: 'labels graph

        '
      id: graph
    - description: 'network output

        '
      id: features
    - description: 'id of the CTC blank label

        '
      id: blankTokenId
    - description: 'label output delay constraint introduced during training that
        allows to have shorter delay during inference. This is using the original
        time information to enforce that CTC tokens only get aligned within a time
        margin. Setting this parameter smaller will result in shorted delay between
        label output during decoding, yet may hurt accuracy. delayConstraint=-1 means
        no constraint

        '
      id: delayConstraint
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.forward_backward
- example:
  - "\n```\n\n>>> c = np.asarray([[[0],[1]],[[4],[5]]]).astype('f')\n>>> x = C.input_variable((2,1))\n\
    >>> d = np.arange(12).reshape(6,2).astype('f')\n>>> y = C.constant(d)\n>>> C.gather(y,\
    \ x).eval({x:c})\narray([[[[  0.,   1.]],\n<BLANKLINE>\n        [[  2.,   3.]]],\n\
    <BLANKLINE>\n<BLANKLINE>\n       [[[  8.,   9.]],\n<BLANKLINE>\n        [[ 10.,\
    \  11.]]]], dtype=float32)\n```\n"
  fullName: cntk.ops.gather
  langs:
  - python
  module: cntk.ops
  name: gather
  source:
    id: gather
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 2174
  summary: 'Retrieves the elements of indices in the tensor reference.

    '
  syntax:
    content: gather(reference, indices)
    parameters:
    - description: 'A tensor

        '
      id: reference
    - description: 'An integer tensor of indices

        '
      id: indices
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.gather
- example:
  - '

    ```


    >>> C.greater([41., 42., 43.], [42., 42., 42.]).eval()

    array([ 0.,  0.,  1.], dtype=float32)

    ```



    ```


    >>> C.greater([-1,0,1], [0]).eval()

    array([ 0.,  0.,  1.], dtype=float32)

    ```

    '
  fullName: cntk.ops.greater
  langs:
  - python
  module: cntk.ops
  name: greater
  source:
    id: greater
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 562
  summary: 'Elementwise ''greater'' comparison of two tensors. Result is 1 if left
    > right else 0.

    '
  syntax:
    content: greater(left, right, name='')
    parameters:
    - description: 'left side tensor

        '
      id: left
    - description: 'right side tensor

        '
      id: right
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.greater
- example:
  - '

    ```


    >>> C.greater_equal([41., 42., 43.], [42., 42., 42.]).eval()

    array([ 0.,  1.,  1.], dtype=float32)

    ```



    ```


    >>> C.greater_equal([-1,0,1], [0]).eval()

    array([ 0.,  1.,  1.], dtype=float32)

    ```

    '
  fullName: cntk.ops.greater_equal
  langs:
  - python
  module: cntk.ops
  name: greater_equal
  source:
    id: greater_equal
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 588
  summary: 'Elementwise ''greater equal'' comparison of two tensors. Result is 1 if
    left >= right else 0.

    '
  syntax:
    content: greater_equal(left, right, name='')
    parameters:
    - description: 'left side tensor

        '
      id: left
    - description: 'right side tensor

        '
      id: right
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.greater_equal
- example:
  - '

    ```


    >>> C.hardmax([1., 1., 2., 3.]).eval()

    array([ 0.,  0.,  0.,  1.], dtype=float32)

    ```



    ```


    >>> C.hardmax([1., 3., 2., 3.]).eval()

    array([ 0.,  1.,  0.,  0.], dtype=float32)

    ```

    '
  fullName: cntk.ops.hardmax
  langs:
  - python
  module: cntk.ops
  name: hardmax
  source:
    id: hardmax
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 1572
  summary: 'Creates a tensor with the same shape as the input tensor, with zeros everywhere
    and a 1.0 where the

    maximum value of the input tensor is located. If the maximum value is repeated,
    1.0 is placed in the first location found.

    '
  syntax:
    content: hardmax(x, name='')
    parameters:
    - description: 'numpy array or any @cntk.ops.functions.Function that outputs a
        tensor

        '
      id: x
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.hardmax
- fullName: cntk.ops.input
  langs:
  - python
  module: cntk.ops
  name: input
  source:
    id: input
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 2773
  summary: 'DEPRECATED.


    It creates an input in the network: a place where data,

    such as features and labels, should be provided.

    '
  syntax:
    content: input(shape, dtype=<cntk.default_options.default_override_or object>,
      needs_gradient=False, is_sparse=False, dynamic_axes=[Axis('defaultBatchAxis')],
      name='')
    parameters:
    - description: 'the shape of the input tensor

        '
      id: shape
      type:
      - tuple or int
    - description: 'data type. Default is np.float32.

        '
      id: dtype
      type:
      - np.float32 or np.float64
    - description: 'whether to back-propagates to it or not. False by default.

        '
      id: needs_gradients
      type:
      - bool, optional
    - description: 'whether the variable is sparse (*False* by default)

        '
      id: is_sparse
      type:
      - bool, optional
    - description: 'a list of dynamic axis (e.g., batch axis, sequence axis)

        '
      id: dynamic_axes
      type:
      - list or tuple, default
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.variables.Variable

        '
  type: function
  uid: cntk.ops.input
- fullName: cntk.ops.input_variable
  langs:
  - python
  module: cntk.ops
  name: input_variable
  source:
    id: input_variable
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 2799
  summary: 'It creates an input in the network: a place where data,

    such as features and labels, should be provided.

    '
  syntax:
    content: input_variable(shape, dtype=np.float32, needs_gradient=False, is_sparse=False,
      dynamic_axes=[Axis.default_batch_axis()], name='')
    parameters:
    - description: 'the shape of the input tensor

        '
      id: shape
      type:
      - tuple or int
    - description: 'data type. Default is np.float32.

        '
      id: dtype
      type:
      - np.float32 or np.float64
    - description: 'whether to back-propagates to it or not. False by default.

        '
      id: needs_gradients
      type:
      - bool, optional
    - description: 'whether the variable is sparse (*False* by default)

        '
      id: is_sparse
      type:
      - bool, optional
    - description: 'a list of dynamic axis (e.g., batch axis, time axis)

        '
      id: dynamic_axes
      type:
      - list or tuple, default
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.variables.Variable

        '
  type: function
  uid: cntk.ops.input_variable
- example:
  - '

    ```


    >>> num_classes = 2

    >>> labels = C.input_variable((num_classes))

    >>> graph = C.labels_to_graph(labels)

    ```

    '
  fullName: cntk.ops.labels_to_graph
  langs:
  - python
  module: cntk.ops
  name: labels_to_graph
  source:
    id: labels_to_graph
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 168
  summary: 'Conversion node from labels to graph. Typically used as an input to ForwardBackward
    node.

    This node''s objective is to transform input labels into a graph representing
    exact forward-backward criterion.

    '
  syntax:
    content: labels_to_graph(labels, name='')
    parameters:
    - description: 'input training labels

        '
      id: labels
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.labels_to_graph
- example:
  - '

    ```


    >>> C.leaky_relu([[-1, -0.5, 0, 1, 2]]).eval()

    array([[-0.01 , -0.005,  0.   ,  1.   ,  2.   ]], dtype=float32)

    ```

    '
  fullName: cntk.ops.leaky_relu
  langs:
  - python
  module: cntk.ops
  name: leaky_relu
  source:
    id: leaky_relu
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 1301
  summary: 'Leaky Rectified linear operation. Computes the element-wise leaky rectified
    linear

    of `x`: `max(x, 0)` for `x >= 0` and `x`: `0.01*x` otherwise.


    The output tensor has the same shape as `x`.

    '
  syntax:
    content: leaky_relu(x, name='')
    parameters:
    - description: 'any @cntk.ops.functions.Function that outputs a tensor.

        '
      id: x
      type:
      - 'numpy.array or @cntk.ops.functions.Function

        '
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, default to ''
    return:
      description: 'An instance of @cntk.ops.functions.Function

        '
      type:
      - cntk.ops.functions.Function
  type: function
  uid: cntk.ops.leaky_relu
- example:
  - '

    ```


    >>> C.less([41., 42., 43.], [42., 42., 42.]).eval()

    array([ 1.,  0.,  0.], dtype=float32)

    ```



    ```


    >>> C.less([-1,0,1], [0]).eval()

    array([ 1.,  0.,  0.], dtype=float32)

    ```

    '
  fullName: cntk.ops.less
  langs:
  - python
  module: cntk.ops
  name: less
  source:
    id: less
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 510
  summary: 'Elementwise ''less'' comparison of two tensors. Result is 1 if left <
    right else 0.

    '
  syntax:
    content: less(left, right, name='')
    parameters:
    - description: 'left side tensor

        '
      id: left
    - description: 'right side tensor

        '
      id: right
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.less
- example:
  - '

    ```


    >>> C.less_equal([41., 42., 43.], [42., 42., 42.]).eval()

    array([ 1.,  1.,  0.], dtype=float32)

    ```



    ```


    >>> C.less_equal([-1,0,1], [0]).eval()

    array([ 1.,  1.,  0.], dtype=float32)

    ```

    '
  fullName: cntk.ops.less_equal
  langs:
  - python
  module: cntk.ops
  name: less_equal
  source:
    id: less_equal
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 640
  summary: 'Elementwise ''less equal'' comparison of two tensors. Result is 1 if left
    <= right else 0.

    '
  syntax:
    content: less_equal(left, right, name='')
    parameters:
    - description: 'left side tensor

        '
      id: left
    - description: 'right side tensor

        '
      id: right
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.less_equal
- example:
  - '

    ```


    >>> C.log([1., 2.]).eval()

    array([ 0.      ,  0.693147], dtype=float32)

    ```

    '
  fullName: cntk.ops.log
  langs:
  - python
  module: cntk.ops
  name: log
  source:
    id: log
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 1618
  summary: "Computes the element-wise the natural logarithm of `x`:\n\nNote: CNTK\
    \ returns -85.1 for log(x) if `x` is negative or zero. The reason is that it uses\
    \ 1e-37 (whose natural logarithm is -85.1) as the smallest float number for *log*,\
    \ because this is the only guaranteed precision across platforms. This will be\
    \ changed to return *NaN* and *-inf*. \n"
  syntax:
    content: log(x, name='')
    parameters:
    - description: 'numpy array or any @cntk.ops.functions.Function that outputs a
        tensor

        '
      id: x
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.log
- example:
  - '

    ```


    >>> a = np.arange(3,dtype=np.float32)

    >>> np.exp(C.log_add_exp(np.log(1+a), np.log(1+a*a)).eval())

    array([ 2.,  4.,  8.], dtype=float32)

    >>> np.exp(C.log_add_exp(np.log(1+a), [0.]).eval())

    array([ 2.,  3.,  4.], dtype=float32)

    ```

    '
  fullName: cntk.ops.log_add_exp
  langs:
  - python
  module: cntk.ops
  name: log_add_exp
  source:
    id: log_add_exp
    path: bindings/python/cntk\ops\__init__.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\ops\__init__.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 910
  summary: 'Calculates the log of the sum of the exponentials

    of the two or more input tensors. It supports broadcasting.

    '
  syntax:
    content: log_add_exp(left, right, name='')
    parameters:
    - description: 'left side tensor

        '
      id: arg1
    - description: 'right side tensor

        '
      id: arg2
    - &id005
      description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    - *id005
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.log_add_exp
- example:
  - "\n```\n\n>>> C.minus([1, 2, 3], [4, 5, 6]).eval()\narray([-3., -3., -3.], dtype=float32)\n\
    ```\n\n\n```\n\n>>> C.minus([[1,2],[3,4]], 1).eval()\narray([[ 0.,  1.],\n   \
    \    [ 2.,  3.]], dtype=float32)\n```\n"
  fullName: cntk.ops.minus
  langs:
  - python
  module: cntk.ops
  name: minus
  source:
    id: minus
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 751
  summary: 'The output of this operation is left minus right tensor. It supports broadcasting.

    '
  syntax:
    content: minus(left, right, name='')
    parameters:
    - description: 'left side tensor

        '
      id: left
    - description: 'right side tensor

        '
      id: right
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.minus
- example:
  - '

    ```


    >>> C.negate([-1, 1, -2, 3]).eval()

    array([ 1., -1.,  2., -3.], dtype=float32)

    ```

    '
  fullName: cntk.ops.negate
  langs:
  - python
  module: cntk.ops
  name: negate
  source:
    id: negate
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 1712
  summary: 'Computes the element-wise negation of `x`:


    '
  syntax:
    content: negate(x, name='')
    parameters:
    - description: 'numpy array or any @cntk.ops.functions.Function that outputs a
        tensor

        '
      id: x
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.negate
- example:
  - '

    ```


    >>> C.not_equal([41., 42., 43.], [42., 42., 42.]).eval()

    array([ 1.,  0.,  1.], dtype=float32)

    ```



    ```


    >>> C.not_equal([-1,0,1], [0]).eval()

    array([ 1.,  0.,  1.], dtype=float32)

    ```

    '
  fullName: cntk.ops.not_equal
  langs:
  - python
  module: cntk.ops
  name: not_equal
  source:
    id: not_equal
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 614
  summary: 'Elementwise ''not equal'' comparison of two tensors. Result is 1 if left
    != right else 0.

    '
  syntax:
    content: not_equal(left, right, name='')
    parameters:
    - description: 'left side tensor

        '
      id: left
    - description: 'right side tensor

        '
      id: right
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.not_equal
- example:
  - "\n```\n\n>>> data = np.asarray([[1, 2],\n...                    [4, 5]], dtype=np.float32)\n\
    ```\n\n\n```\n\n>>> x = C.input_variable((2,))\n>>> C.one_hot(x, 6, False).eval({x:data})\n\
    array([[[ 0.,  1.,  0.,  0.,  0.,  0.],\n        [ 0.,  0.,  1.,  0.,  0.,  0.]],\n\
    <BLANKLINE>\n        [[ 0.,  0.,  0.,  0.,  1.,  0.],\n         [ 0.,  0.,  0.,\
    \  0.,  0.,  1.]]], dtype=float32)\n```\n"
  fullName: cntk.ops.one_hot
  langs:
  - python
  module: cntk.ops
  name: one_hot
  source:
    id: one_hot
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 2142
  summary: 'Create one hot tensor based on the input tensor

    '
  syntax:
    content: one_hot(x, num_classes, sparse_output=False, axis=-1, name='')
    parameters:
    - description: 'input tensor, the value must be positive integer and less than
        num_class

        '
      id: x
    - description: 'the number of class in one hot tensor

        '
      id: num_classes
    - description: 'if set as True, we will create the one hot tensor as sparse.

        '
      id: sparse_output
    - description: 'The axis to fill (default: -1, a new inner-most axis).

        '
      id: axis
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional, keyword only
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.one_hot
- example:
  - "\n```\n\n>>> from _cntk_py import constant_initializer\n>>> W = C.parameter((C.InferredDimension,4),\
    \ constant_initializer(0.1))\n>>> x = C.input_variable(shape=(4,))\n>>> s = np.reshape(np.arange(20.0,\
    \ dtype=np.float32), (5,4))\n>>> t = np.reshape(np.arange(12.0, dtype=np.float32),\
    \ (3,4))\n>>> f = C.optimized_rnnstack(x, W, 8, 2) # doctest: +SKIP\n>>> r = f.eval({x:[s,t]})\
    \                # doctest: +SKIP\n>>> len(r)                               #\
    \ doctest: +SKIP\n2\n>>> print(*r[0].shape)                   # doctest: +SKIP\n\
    5 8\n>>> print(*r[1].shape)                   # doctest: +SKIP\n3 8\n>>> r[0][:3,:]-r[1]\
    \                      # doctest: +SKIP\narray([[ 0.,  0.,  0.,  0.,  0.,  0.,\
    \  0.,  0.],\n       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n       [ 0., \
    \ 0.,  0.,  0.,  0.,  0.,  0.,  0.]], dtype=float32)\n```\n"
  fullName: cntk.ops.optimized_rnnstack
  langs:
  - python
  module: cntk.ops
  name: optimized_rnnstack
  source:
    id: optimized_rnnstack
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 1781
  summary: 'An RNN implementation that uses the primitives in cuDNN.

    If cuDNN is not available it fails. You can use @cntk.misc.optimized_rnnstack_converter.convert_optimized_rnnstack

    to convert a model to GEMM-based implementation when no cuDNN.

    '
  syntax:
    content: optimized_rnnstack(operand, weights, hidden_size, num_layers, bidirectional=False,
      recurrent_op='lstm', name='')
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.optimized_rnnstack
- fullName: cntk.ops.output_variable
  langs:
  - python
  module: cntk.ops
  name: output_variable
  source:
    id: output_variable
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 2834
  summary: 'It creates an output variable that is used to define a user defined function.

    '
  syntax:
    content: output_variable(shape, dtype, dynamic_axes, needs_gradient=True, name='')
    parameters:
    - description: 'the shape of the input tensor

        '
      id: shape
      type:
      - tuple or int
    - description: 'data type

        '
      id: dtype
      type:
      - np.float32 or np.float64
    - description: 'a list of dynamic axis (e.g., batch axis, time axis)

        '
      id: dynamic_axes
      type:
      - list or tuple
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.variables.Variable that is of output type

        '
  type: function
  uid: cntk.ops.output_variable
- example:
  - '

    ```


    >>> alpha = C.constant(value=[[0.5, 0.5, 0.5, 0.5, 0.5]])

    >>> C.param_relu(alpha, [[-1, -0.5, 0, 1, 2]]).eval()

    array([[-0.5 , -0.25,  0.  ,  1.  ,  2.  ]], dtype=float32)

    ```

    '
  fullName: cntk.ops.param_relu
  langs:
  - python
  module: cntk.ops
  name: param_relu
  source:
    id: param_relu
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 1325
  summary: 'Parametric rectified linear operation. Computes the element-wise parameteric
    rectified linear

    of `x`: `max(x, 0)` for `x >= 0` and `x`: `alpha*x` otherwise.


    The output tensor has the same shape as `x`.

    '
  syntax:
    content: param_relu(alpha, x, name='')
    parameters:
    - description: 'same shape as x

        '
      id: alpha
      type:
      - cntk.variables.Parameter
    - description: 'any @cntk.ops.functions.Function that outputs a tensor.

        '
      id: x
      type:
      - 'numpy.array or @cntk.ops.functions.Function

        '
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, default to ''
    return:
      description: 'An instance of @cntk.ops.functions.Function

        '
      type:
      - cntk.ops.functions.Function
  type: function
  uid: cntk.ops.param_relu
- example:
  - "\n```\n\n>>> init_parameter = C.parameter(shape=(3,4), init=2)\n>>> np.asarray(init_parameter)\
    \ # doctest: +SKIP\narray([[ 2.,  2.,  2.,  2.],\n       [ 2.,  2.,  2.,  2.],\n\
    \       [ 2.,  2.,  2.,  2.]], dtype=float32)\n```\n"
  fullName: cntk.ops.parameter
  langs:
  - python
  module: cntk.ops
  name: parameter
  source:
    id: parameter
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 2891
  summary: 'It creates a parameter tensor.

    '
  syntax:
    content: parameter(shape=None, init=None, dtype=None, device=None, name='')
    parameters:
    - description: 'the shape of the input tensor. If not provided, it

        will be inferred from `value`.

        '
      id: shape
      type:
      - tuple or int, optional
    - description: 'if init is a scalar

        it will be replicated for every element in the tensor or

        NumPy array. If it is the output of an initializer form

        @cntk.initializer it will be used to initialize the tensor at

        the first forward pass. If *None*, the tensor will be initialized

        with 0.

        '
      id: init
      type:
      - scalar or NumPy array or initializer
    - description: 'data type of the constant. If a NumPy array and `dtype`,

        are given, then data will be converted if needed. If none given, it will default
        to `np.float32`.

        '
      id: dtype
      type:
      - optional
    - description: 'instance of DeviceDescriptor

        '
      id: device
      type:
      - cntk.device.DeviceDescriptor
    - description: 'the name of the Parameter instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.variables.Parameter

        '
  type: function
  uid: cntk.ops.parameter
- fullName: cntk.ops.per_dim_mean_variance_normalize
  langs:
  - python
  module: cntk.ops
  name: per_dim_mean_variance_normalize
  source:
    id: per_dim_mean_variance_normalize
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 2960
  summary: 'Computes per dimension mean-variance normalization of the specified input
    operand.

    '
  syntax:
    content: per_dim_mean_variance_normalize(operand, mean, inv_stddev, name='')
    parameters:
    - description: 'the variable to be normalized

        '
      id: operand
    - description: 'per dimension mean to use for the normalization

        '
      id: mean
      type:
      - NumPy array
    - description: 'per dimension standard deviation to use for the normalization

        '
      id: inv_stddev
      type:
      - NumPy array
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.per_dim_mean_variance_normalize
- fullName: cntk.ops.placeholder
  langs:
  - python
  module: cntk.ops
  name: placeholder
  source:
    id: placeholder
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 2862
  summary: 'It creates a placeholder variable that has to be later bound to an actual
    variable.

    A common use of this is to serve as a placeholder for a later output variable
    in a

    recurrent network, which is replaced with the actual output variable by calling

    replace_placeholder(s).

    '
  syntax:
    content: placeholder(shape=None, dynamic_axes=None, name='')
    parameters:
    - description: 'the shape of the variable tensor

        '
      id: shape
      type:
      - tuple or int
    - description: 'the list of dynamic axes that the actual variable uses

        '
      id: dynamic_axes
      type:
      - list
    - description: 'the name of the placeholder variable in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.variables.Variable

        '
  type: function
  uid: cntk.ops.placeholder
- example:
  - '

    ```


    >>> C.plus([1, 2, 3], [4, 5, 6]).eval()

    array([ 5.,  7.,  9.], dtype=float32)

    ```



    ```


    >>> C.plus([-5, -4, -3, -2, -1], [10]).eval()

    array([ 5.,  6.,  7.,  8.,  9.], dtype=float32)

    ```



    ```


    >>> C.plus([-5, -4, -3, -2, -1], [10], [3, 2, 3, 2, 3], [-13], [+42], ''multi_arg_example'').eval()

    array([ 37.,  37.,  39.,  39.,  41.], dtype=float32)

    ```



    ```


    >>> C.plus([-5, -4, -3, -2, -1], [10], [3, 2, 3, 2, 3]).eval()

    array([  8.,   8.,  10.,  10.,  12.], dtype=float32)

    ```

    '
  fullName: cntk.ops.plus
  langs:
  - python
  module: cntk.ops
  name: plus
  source:
    id: plus
    path: bindings/python/cntk\ops\__init__.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\ops\__init__.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 717
  summary: 'The output of this operation is the sum of the two or more input tensors.
    It supports broadcasting.

    '
  syntax:
    content: plus(left, right, name='')
    parameters:
    - description: 'left side tensor

        '
      id: arg1
    - description: 'right side tensor

        '
      id: arg2
    - &id006
      description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    - *id006
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.plus
- example:
  - "\n```\n\n>>> img = np.reshape(np.arange(16, dtype = np.float32), [1, 4, 4])\n\
    >>> x = C.input_variable(img.shape)\n>>> C.pooling(x, C.AVG_POOLING, (2,2), (2,2)).eval({x\
    \ : [img]})\narray([[[[  2.5,   4.5],\n          [ 10.5,  12.5]]]], dtype=float32)\n\
    >>> C.pooling(x, C.MAX_POOLING, (2,2), (2,2)).eval({x : [img]})\narray([[[[  5.,\
    \   7.],\n          [ 13.,  15.]]]], dtype=float32)\n```\n"
  fullName: cntk.ops.pooling
  langs:
  - python
  module: cntk.ops
  name: pooling
  source:
    id: pooling
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 381
  summary: 'The pooling operations compute a new tensor by selecting the maximum or
    average value in the pooling input.

    In the case of average pooling with padding, the average is only over the valid
    region.


    N-dimensional pooling allows to create max or average pooling of any dimensions,
    stride or padding.

    '
  syntax:
    content: pooling(operand, pooling_type, pooling_window_shape, strides=(1,), auto_padding=[False],
      ceil_out_dim=False, include_pad=False, name='')
    parameters:
    - description: 'pooling input

        '
      id: operand
    - description: 'one of @cntk.ops.MAX_POOLING or @cntk.ops.AVG_POOLING

        '
      id: pooling_type
    - description: 'dimensions of the pooling window

        '
      id: pooling_window_shape
    - description: 'strides.

        '
      id: strides
      type:
      - default 1
    - description: 'automatic padding flags for each input dimension.

        '
      id: auto_padding
      type:
      - default [False,]
    - description: 'ceiling while computing output size

        '
      id: ceil_out_dim
      type:
      - default False
    - description: 'include pad while average pooling

        '
      id: include_pad
      type:
      - default False
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.pooling
- example:
  - "\n```\n\n>>> C.pow([1, 2, -2], [3, -2, 3]).eval()\narray([ 1.  ,  0.25, -8. \
    \ ], dtype=float32)\n```\n\n\n```\n\n>>> C.pow([[0.5, 2],[4, 1]], -2).eval()\n\
    array([[ 4.    ,  0.25  ],\n       [ 0.0625,  1.    ]], dtype=float32)\n```\n"
  fullName: cntk.ops.pow
  langs:
  - python
  module: cntk.ops
  name: pow
  source:
    id: pow
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 778
  summary: 'Computes *base* raised to the power of *exponent*. It supports broadcasting.

    This is well defined if *base* is non-negative or *exponent* is an integer.

    Otherwise the result is NaN. The gradient with respect to the base is  well

    defined if the forward operation is well defined. The gradient with respect

    to the exponent is well defined if the base is non-negative, and it is set

    to 0 otherwise.

    '
  syntax:
    content: pow(base, exponent, name='')
    parameters:
    - description: 'base tensor

        '
      id: base
    - description: 'exponent tensor

        '
      id: exponent
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.pow
- fullName: cntk.ops.random_sample
  langs:
  - python
  module: cntk.ops
  name: random_sample
  source:
    id: random_sample
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 2614
  summary: 'Estimates inclusion frequencies for random sampling with or without

    replacement.


    The output value is a set of num_samples random samples represented

    by a (sparse) matrix of shape [num_samples x len(weights)],

    where len(weights) is the number of classes (categories) to choose

    from. The output has no dynamic axis.

    The samples are drawn according to the weight vector p(i) =

    weights[i] / sum(weights)

    We get one set of samples per minibatch.

    Intended use cases are e.g. sampled softmax, noise contrastive

    estimation etc.

    '
  syntax:
    content: random_sample(weights, num_samples, allow_duplicates, seed=4294967293,
      name='')
    parameters:
    - description: 'input vector of sampling weights which should be

        non-negative numbers.

        '
      id: weights
    - description: 'number of expected samples

        '
      id: num_samples
      type:
      - int
    - description: 'If sampling is done

        with replacement (*True*) or without (*False*).

        '
      id: allow_duplicates
      type:
      - bool
    - description: 'random seed.

        '
      id: seed
      type:
      - int
    - description: 'the name of the Function instance in the network.

        '
      id: name
      type:
      - 'cntk.ops.str

        , optional'
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.random_sample
- example:
  - '

    ```


    >>> import numpy as np

    >>> from cntk import *

    >>> # weight vector with 100 ''1000''-values followed

    >>> # by 100 ''1'' values

    >>> w1 = np.full((100),1000, dtype = np.float)

    >>> w2 = np.full((100),1, dtype = np.float)

    >>> w = np.concatenate((w1, w2))

    >>> f = random_sample_inclusion_frequency(w, 150, True).eval()

    >>> f[0]

    1.4985015

    >>> f[1]

    1.4985015

    >>> f[110]

    0.0014985015

    >>> # when switching to sampling without duplicates samples are

    >>> # forced to pick the low weight classes too

    >>> f = random_sample_inclusion_frequency(w, 150, False).eval()

    >>> f[0]

    1.0

    ```

    '
  fullName: cntk.ops.random_sample_inclusion_frequency
  langs:
  - python
  module: cntk.ops
  name: random_sample_inclusion_frequency
  source:
    id: random_sample_inclusion_frequency
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 2654
  summary: 'For weighted sampling with the specifed sample size (*num_samples*)

    this operation computes the expected number of occurrences of each class

    in the sampled set. In case of sampling without replacement

    the result is only an estimate which might be quite rough in the

    case of small sample sizes.

    Intended uses are e.g. sampled softmax, noise contrastive

    estimation etc.

    This operation will be typically used together

    with @cntk.ops.random_sample.

    '
  syntax:
    content: random_sample_inclusion_frequency(weights, num_samples, allow_duplicates,
      seed=4294967293, name='')
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.random_sample_inclusion_frequency
- example:
  - '

    ```


    >>> C.reciprocal([-1/3, 1/5, -2, 3]).eval()

    array([-3.      ,  5.      , -0.5     ,  0.333333], dtype=float32)

    ```

    '
  fullName: cntk.ops.reciprocal
  langs:
  - python
  module: cntk.ops
  name: reciprocal
  source:
    id: reciprocal
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 1734
  summary: 'Computes the element-wise reciprocal of `x`:

    '
  syntax:
    content: reciprocal(x, name='')
    parameters:
    - description: 'numpy array or any @cntk.ops.functions.Function that outputs a
        tensor

        '
      id: x
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.reciprocal
- fullName: cntk.ops.reconcile_dynamic_axes
  langs:
  - python
  module: cntk.ops
  name: reconcile_dynamic_axes
  source:
    id: reconcile_dynamic_axes
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 145
  summary: "   Create a new Function instance which reconciles the dynamic axes of\
    \ the\n   specified tensor operands. The output of the returned Function has the\
    \ sample\n   layout of the 'x' operand and the dynamic axes of the 'dynamic_axes_as'\
    \ operand.\n   This operator also performs a runtime check to ensure that the\
    \ dynamic axes layouts\n   of the 2 operands indeed match.\n"
  syntax:
    content: reconcile_dynamic_axes(x, dynamic_axes_as, name='')
    parameters:
    - description: 'The Function/Variable, whose dynamic axes are to be reconciled

        '
      id: x
    - description: 'The Function/Variable, to whose dynamic axes the

        operand ''x''''s dynamic axes are reconciled to.

        '
      id: dynamic_axes_as
    - description: 'the name of the reconcile_dynamic_axes Function in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.reconcile_dynamic_axes
- example:
  - "\n```\n\n>>> # create 3x2x2 matrix in a sequence of length 1 in a batch of one\
    \ sample\n>>> data = np.array([[[5,1], [20,2]],[[30,1], [40,2]],[[55,1], [60,2]]],\
    \ dtype=np.float32)\n```\n\n\n```\n\n>>> C.reduce_log_sum_exp(data, axis=0).eval().round(4)\n\
    array([[[ 55.      ,   2.0986],\n        [ 60.      ,   3.0986]]], dtype=float32)\n\
    >>> np.log(np.sum(np.exp(data), axis=0)).round(4)\narray([[ 55.      ,   2.0986],\n\
    \       [ 60.      ,   3.0986]], dtype=float32)\n>>> C.reduce_log_sum_exp(data,\
    \ axis=(0,2)).eval().round(4)\narray([[[ 55.],\n        [ 60.]]], dtype=float32)\n\
    >>> np.log(np.sum(np.exp(data), axis=(0,2))).round(4)\narray([ 55.,  60.], dtype=float32)\n\
    ```\n\n\n```\n\n>>> x = C.input_variable(shape=(2,2))\n>>> lse = C.reduce_log_sum_exp(x,\
    \ axis=[C.axis.Axis.default_batch_axis(), 1])\n>>> lse.eval({x:data}).round(4)\n\
    array([[ 55.],\n       [ 60.]], dtype=float32)\n>>> np.log(np.sum(np.exp(data),\
    \ axis=(0,2))).round(4)\narray([ 55.,  60.], dtype=float32)\n```\n"
  fullName: cntk.ops.reduce_log_sum_exp
  langs:
  - python
  module: cntk.ops
  name: reduce_log_sum_exp
  source:
    id: reduce_log_sum_exp
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 2257
  summary: 'Computes the log of the sum of the exponentiations of the input tensor''s

    elements across a specified axis or a list of specified axes.


    Note that CNTK keeps the shape of the resulting tensors when reducing over multiple
    static axes.

    '
  syntax:
    content: reduce_log_sum_exp(x, axis=None, name='')
    parameters:
    - description: 'input tensor

        '
      id: x
    - description: 'axis along which the reduction will be performed

        '
      id: axis
      type:
      - "int or @cntk.axis.Axis\n or a @list\n or @tuple\n of int or @cntk.axis.Axis\n"
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.reduce_log_sum_exp
- example:
  - "\n```\n\n>>> # create 3x2x2 matrix in a sequence of length 1 in a batch of one\
    \ sample\n>>> data = np.array([[[5,1], [20,2]],[[30,1], [40,2]],[[55,1], [60,2]]],\
    \ dtype=np.float32)\n```\n\n\n```\n\n>>> C.reduce_max(data, 0).eval().round(4)\n\
    array([[[ 55.,   1.],\n        [ 60.,   2.]]], dtype=float32)\n>>> C.reduce_max(data,\
    \ 1).eval().round(4)\narray([[[ 20.,   2.]],\n<BLANKLINE>\n       [[ 40.,   2.]],\n\
    <BLANKLINE>\n       [[ 60.,   2.]]], dtype=float32)\n>>> C.reduce_max(data, (0,2)).eval().round(4)\n\
    array([[[ 55.],\n        [ 60.]]], dtype=float32)\n```\n\n\n```\n\n>>> x = C.input_variable((2,2))\n\
    >>> C.reduce_max( x * 1.0, (C.Axis.default_batch_axis(), 1)).eval({x: data}).round(4)\n\
    array([[ 55.],\n       [ 60.]], dtype=float32)\n```\n"
  fullName: cntk.ops.reduce_max
  langs:
  - python
  module: cntk.ops
  name: reduce_max
  source:
    id: reduce_max
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 2354
  summary: 'Computes the max of the input tensor''s elements across a specified axis
    or a list of specified axes.


    Note that CNTK keeps the shape of the resulting tensors when reducing over multiple
    static axes.

    '
  syntax:
    content: reduce_max(x, axis=None, name='')
    parameters:
    - description: 'input tensor

        '
      id: x
    - description: 'axis along which the reduction will be performed

        '
      id: axis
      type:
      - "int or @cntk.axis.Axis\n or a @list\n or @tuple\n of int or @cntk.axis.Axis\n"
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.reduce_max
- example:
  - "\n```\n\n>>> # create 3x2x2 matrix in a sequence of length 1 in a batch of one\
    \ sample\n>>> data = np.array([[[5,1], [20,2]],[[30,1], [40,2]],[[55,1], [60,2]]],\
    \ dtype=np.float32)\n```\n\n\n```\n\n>>> C.reduce_mean(data, 0).eval().round(4)\n\
    array([[[ 30.,   1.],\n        [ 40.,   2.]]], dtype=float32)\n>>> np.mean(data,\
    \ axis=0).round(4)\narray([[ 30.,   1.],\n       [ 40.,   2.]], dtype=float32)\n\
    >>> C.reduce_mean(data, 1).eval().round(4)\narray([[[ 12.5,   1.5]],\n<BLANKLINE>\n\
    \       [[ 35. ,   1.5]],\n<BLANKLINE>\n       [[ 57.5,   1.5]]], dtype=float32)\n\
    >>> np.mean(data, axis=1).round(4)\narray([[ 12.5,   1.5],\n       [ 35. ,   1.5],\n\
    \       [ 57.5,   1.5]], dtype=float32)\n>>> C.reduce_mean(data, (0,2)).eval().round(4)\n\
    array([[[ 15.5],\n        [ 21. ]]], dtype=float32)\n```\n\n\n```\n\n>>> x = C.input_variable((2,2))\n\
    >>> C.reduce_mean( x * 1.0, (C.Axis.default_batch_axis(), 1)).eval({x: data}).round(4)\n\
    array([[ 15.5],\n       [ 21.      ]], dtype=float32)\n```\n"
  fullName: cntk.ops.reduce_mean
  langs:
  - python
  module: cntk.ops
  name: reduce_mean
  source:
    id: reduce_mean
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 2304
  summary: 'Computes the mean of the input tensor''s elements across a specified axis
    or a list of specified axes.

    '
  syntax:
    content: reduce_mean(x, axis=None, name='')
    parameters:
    - description: 'input tensor

        '
      id: x
    - description: 'axis along which the reduction will be performed

        '
      id: axis
      type:
      - "int or @cntk.axis.Axis\n or a @list\n or @tuple\n of int or @cntk.axis.Axis\n"
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function


        Note that CNTK keeps the shape of the resulting tensors when reducing over
        multiple static axes.

        '
  type: function
  uid: cntk.ops.reduce_mean
- example:
  - "\n```\n\n>>> # create 3x2x2 matrix in a sequence of length 1 in a batch of one\
    \ sample\n>>> data = np.array([[[5,1], [20,2]],[[30,1], [40,2]],[[55,1], [60,2]]],\
    \ dtype=np.float32)\n```\n\n\n```\n\n>>> C.reduce_min(data, 0).eval().round(4)\n\
    array([[[  5.,   1.],\n        [ 20.,   2.]]], dtype=float32)\n>>> C.reduce_min(data,\
    \ 1).eval().round(4)\narray([[[  5.,   1.]],\n<BLANKLINE>\n       [[ 30.,   1.]],\n\
    <BLANKLINE>\n       [[ 55.,   1.]]], dtype=float32)\n>>> C.reduce_min(data, (0,2)).eval().round(4)\n\
    array([[[ 1.],\n        [ 2.]]], dtype=float32)\n```\n\n\n```\n\n>>> x = C.input_variable((2,2))\n\
    >>> C.reduce_min( x * 1.0, (C.Axis.default_batch_axis(), 1)).eval({x: data}).round(4)\n\
    array([[ 1.],\n       [ 2.]], dtype=float32)\n```\n"
  fullName: cntk.ops.reduce_min
  langs:
  - python
  module: cntk.ops
  name: reduce_min
  source:
    id: reduce_min
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 2397
  summary: 'Computes the min of the input tensor''s elements across a specified axis
    or a list of specified axes.

    '
  syntax:
    content: reduce_min(x, axis=None, name='')
    parameters:
    - description: 'input tensor

        '
      id: x
    - description: 'axis along which the reduction will be performed

        '
      id: axis
      type:
      - "int or @cntk.axis.Axis\n or a list of integers or a list of @cntk.axis.Axis\n"
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str
    return:
      description: '@cntk.ops.functions.Function


        Note that CNTK keeps the shape of the resulting tensors when reducing over
        multiple static axes.

        '
  type: function
  uid: cntk.ops.reduce_min
- example:
  - "\n```\n\n>>> # create 3x2x2 matrix in a sequence of length 1 in a batch of one\
    \ sample\n>>> data = np.array([[[5,1], [20,2]],[[30,1], [40,2]],[[55,1], [60,2]]],\
    \ dtype=np.float32)\n```\n\n\n```\n\n>>> C.reduce_prod(data, 0).eval().round(4)\n\
    array([[[  8250.,      1.],\n        [ 48000.,      8.]]], dtype=float32)\n>>>\
    \ C.reduce_prod(data, 1).eval().round(4)\narray([[[  100.,     2.]],\n<BLANKLINE>\n\
    \       [[ 1200.,     2.]],\n<BLANKLINE>\n       [[ 3300.,     2.]]], dtype=float32)\n\
    >>> C.reduce_prod(data, (0,2)).eval().round(4)\narray([[[   8250.],\n        [\
    \ 384000.]]], dtype=float32)\n```\n\n\n```\n\n>>> x = C.input_variable((2,2))\n\
    >>> C.reduce_prod( x * 1.0, (C.Axis.default_batch_axis(), 1)).eval({x: data}).round(4)\n\
    array([[   8250.],\n       [ 384000.]], dtype=float32)\n```\n"
  fullName: cntk.ops.reduce_prod
  langs:
  - python
  module: cntk.ops
  name: reduce_prod
  source:
    id: reduce_prod
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 2440
  summary: 'Computes the min of the input tensor''s elements across the specified
    axis.


    Note that CNTK keeps the shape of the resulting tensors when reducing over multiple
    static axes.

    '
  syntax:
    content: reduce_prod(x, axis=None, name='')
    parameters:
    - description: 'input tensor

        '
      id: x
    - description: 'axis along which the reduction will be performed

        '
      id: axis
      type:
      - "int or @cntk.axis.Axis\n or a @list\n or @tuple\n of int or @cntk.axis.Axis\n"
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.reduce_prod
- example:
  - "\n```\n\n>>> # create 3x2x2 matrix in a sequence of length 1 in a batch of one\
    \ sample\n>>> data = np.array([[[5,1], [20,2]],[[30,1], [40,2]],[[55,1], [60,2]]],\
    \ dtype=np.float32)\n```\n\n\n```\n\n>>> C.reduce_sum(data, 0).eval().round(4)\n\
    array([[[  90.,    3.],\n        [ 120.,    6.]]], dtype=float32)\n>>> np.sum(data,\
    \ axis=0).round(4)\narray([[  90.,    3.],\n       [ 120.,    6.]], dtype=float32)\n\
    >>> C.reduce_sum(data, 1).eval().round(4)\narray([[[  25.,    3.]],\n<BLANKLINE>\n\
    \       [[  70.,    3.]],\n<BLANKLINE>\n       [[ 115.,    3.]]], dtype=float32)\n\
    >>> np.sum(data, axis=1).round(4)\narray([[  25.,    3.],\n       [  70.,    3.],\n\
    \       [ 115.,    3.]], dtype=float32)\n>>> C.reduce_sum(data, (0,2)).eval().round(4)\n\
    array([[[  93.],\n        [ 126.]]], dtype=float32)\n```\n"
  fullName: cntk.ops.reduce_sum
  langs:
  - python
  module: cntk.ops
  name: reduce_sum
  source:
    id: reduce_sum
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 2207
  summary: 'Computes the sum of the input tensor''s elements across one axis or a
    list of axes. If the axis parameter

    is not specified then the sum will be computed over all static axes, which is

    equivalent with specifying `axis=Axis.all_static_axes()`. If

    `axis=Axis.all_axes()` is specified, then the output is a scalar which is the
    sum of all the

    elements in the minibatch. And if `axis=Axis.default_batch_axis()` is specified,
    then the reduction

    will happen across the batch axis (In this case the input must not be a sequence).


    Note that CNTK keeps the shape of the resulting tensors when reducing over multiple
    static axes.

    '
  syntax:
    content: reduce_sum(x, axis=None, name='')
    parameters:
    - description: 'input tensor

        '
      id: x
    - description: 'axis along which the reduction will be performed

        '
      id: axis
      type:
      - "int or @cntk.axis.Axis\n or a @list\n or @tuple\n of int or @cntk.axis.Axis\n"
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.reduce_sum
- example:
  - '

    ```


    >>> C.relu([[-1, -0.5, 0, 1, 2]]).eval()

    array([[ 0.,  0.,  0.,  1.,  2.]], dtype=float32)

    ```

    '
  fullName: cntk.ops.relu
  langs:
  - python
  module: cntk.ops
  name: relu
  source:
    id: relu
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 1229
  summary: 'Rectified linear operation. Computes the element-wise rectified linear

    of `x`: `max(x, 0)`


    The output tensor has the same shape as `x`.

    '
  syntax:
    content: relu(x, name='')
    parameters:
    - description: 'numpy array or any @cntk.ops.functions.Function that outputs a
        tensor

        '
      id: x
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.relu
- example:
  - "\n```\n\n>>> i1 = C.input_variable(shape=(3,2))\n>>> C.reshape(i1, (2,3)).eval({i1:np.asarray([[[[0.,\
    \ 1.],[2., 3.],[4., 5.]]]], dtype=np.float32)})\narray([[[ 0.,  1.,  2.],\n  \
    \       [ 3.,  4.,  5.]]], dtype=float32)\n```\n"
  fullName: cntk.ops.reshape
  langs:
  - python
  module: cntk.ops
  name: reshape
  source:
    id: reshape
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 1840
  summary: 'Reinterpret input samples as having different tensor dimensions

    One dimension may be specified as 0 and will be inferred


    The output tensor has the shape specified by ''shape''.

    '
  syntax:
    content: reshape(x, shape, begin_axis=None, end_axis=None, name='')
    parameters:
    - description: 'tensor to be reshaped

        '
      id: x
    - description: 'a tuple defining the resulting shape. The specified shape tuple

        may contain -1 for at most one axis, which is automatically inferred to the

        correct dimension size by dividing the total size of the sub-shape being reshaped

        with the product of the dimensions of all the non-inferred axes of the replacement

        shape.

        '
      id: shape
      type:
      - tuple
    - description: 'shape replacement begins at this axis. Negative values

        are counting from the end. *None* is the same as 0. To refer to the end of
        the shape tuple,

        pass *Axis.new_leading_axis()*.

        '
      id: begin_axis
      type:
      - int or None
    - description: 'shape replacement ends at this axis (excluding this axis).

        Negative values are counting from the end. *None* refers to the end of the
        shape tuple.

        '
      id: end_axis
      type:
      - int or None
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.reshape
- fullName: cntk.ops.roipooling
  langs:
  - python
  module: cntk.ops
  name: roipooling
  source:
    id: roipooling
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 347
  summary: 'The ROI (Region of Interest) pooling operation pools over sub-regions
    of an input volume and produces

    a fixed sized output volume regardless of the ROI size. It is used for example
    for object detection.


    Each input image has a fixed number of regions of interest, which are specified
    as bounding boxes (x, y, w, h)

    that are relative to the image size [W x H]. This operation can be used as a replacement
    for the final

    pooling layer of an image classification network (as presented in Fast R-CNN and
    others).


    Changed in version 2.1: The signature was updated to match the Caffe implementation:

    the parameters *pooling_type* and *spatial_scale* were added, and

    the coordinates for the parameters *rois* are now absolute to the original image
    size.

    '
  syntax:
    content: roipooling(operand, rois, pooling_type, roi_output_shape, spatial_scale,
      name='')
    parameters:
    - description: 'a convolutional feature map as the input volume ([W x H x C x
        N]).

        '
      id: operand
    - description: 'only @cntk.ops.MAX_POOLING

        '
      id: pooling_type
    - description: 'the coordinates of the ROIs per image ([4 x roisPerImage x N]),
        each ROI is (x1, y1, x2, y2) absolute to original image size.

        '
      id: rois
    - description: 'dimensions (width x height) of the ROI pooling output shape

        '
      id: roi_output_shape
    - description: 'the scale of operand from the original image size.

        '
      id: spatial_scale
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.roipooling
- example:
  - "\n```\n\n>>> C.round([0.2, 1.3, 4., 5.5, 0.0]).eval()\narray([ 0.,  1.,  4.,\
    \  6.,  0.], dtype=float32)\n```\n\n\n```\n\n>>> C.round([[0.6, 3.3], [1.9, 5.6]]).eval()\n\
    array([[ 1.,  3.],\n       [ 2.,  6.]], dtype=float32)\n```\n\n\n```\n\n>>> C.round([-5.5,\
    \ -4.2, -3., -0.7, 0]).eval()\narray([-5., -4., -3., -1.,  0.], dtype=float32)\n\
    ```\n\n\n```\n\n>>> C.round([[-0.6, -4.3], [1.9, -3.2]]).eval()\narray([[-1.,\
    \ -4.],\n       [ 2., -3.]], dtype=float32)\n```\n"
  fullName: cntk.ops.round
  langs:
  - python
  module: cntk.ops
  name: round
  source:
    id: round
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 1157
  summary: 'The output of this operation is the element wise value rounded to the
    nearest integer.

    In case of tie, where element can have exact fractional part of 0.5

    this operation follows "round half-up" tie breaking strategy.

    This is different from the round operation of numpy which follows

    round half to even.

    '
  syntax:
    content: round(arg, name='')
    parameters:
    - description: 'input tensor

        '
      id: arg
    - description: 'the name of the Function instance in the network (optional)

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.round
- example:
  - '

    ```


    >>> C.selu([[-1, -0.5, 0, 1, 2]]).eval()

    array([[-1.111331, -0.691758,  0.      ,  1.050701,  2.101402]], dtype=float32)

    ```

    '
  fullName: cntk.ops.selu
  langs:
  - python
  module: cntk.ops
  name: selu
  source:
    id: selu
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 1276
  summary: 'Scaled exponential linear unit operation. Computes the element-wise exponential
    linear

    of `x`: `scale * x` for `x >= 0` and `x`: `scale * alpha * (exp(x)-1)` otherwise.


    The output tensor has the same shape as `x`.

    '
  syntax:
    content: selu(x, scale=1.0507009873554805, alpha=1.6732632423543772, name='')
    parameters:
    - description: 'any @cntk.ops.functions.Function that outputs a tensor.

        '
      id: x
      type:
      - 'numpy.array or @cntk.ops.functions.Function

        '
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, default to ''
    return:
      description: 'An instance of @cntk.ops.functions.Function

        '
      type:
      - cntk.ops.functions.Function
  type: function
  uid: cntk.ops.selu
- example:
  - '

    ```


    >>> C.sigmoid([-2, -1., 0., 1., 2.]).eval()

    array([ 0.119203,  0.268941,  0.5     ,  0.731059,  0.880797], dtype=float32)

    ```

    '
  fullName: cntk.ops.sigmoid
  langs:
  - python
  module: cntk.ops
  name: sigmoid
  source:
    id: sigmoid
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 1389
  summary: 'Computes the element-wise sigmoid of `x`:



    The output tensor has the same shape as `x`.

    '
  syntax:
    content: sigmoid(x, name='')
    parameters:
    - description: 'numpy array or any @cntk.ops.functions.Function that outputs a
        tensor

        '
      id: x
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.sigmoid
- example:
  - "\n```\n\n>>> np.round(C.sin(np.arcsin([[1,0.5],[-0.25,-0.75]])).eval(),5)\narray([[\
    \ 1.  ,  0.5 ],\n       [-0.25, -0.75]], dtype=float32)\n```\n"
  fullName: cntk.ops.sin
  langs:
  - python
  module: cntk.ops
  name: sin
  source:
    id: sin
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 1435
  summary: 'Computes the element-wise sine of `x`:


    The output tensor has the same shape as `x`.

    '
  syntax:
    content: sin(x, name='')
    parameters:
    - description: 'numpy array or any @cntk.ops.functions.Function that outputs a
        tensor

        '
      id: x
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.sin
- example:
  - "\n```\n\n>>> np.round(C.sinh([[1,0.5],[-0.25,-0.75]]).eval(),5)\narray([[ 1.1752\
    \ ,  0.5211 ],\n       [-0.25261, -0.82232]], dtype=float32)\n```\n"
  fullName: cntk.ops.sinh
  langs:
  - python
  module: cntk.ops
  name: sinh
  source:
    id: sinh
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 1479
  summary: 'Computes the element-wise sinh of `x`:


    The output tensor has the same shape as `x`.

    '
  syntax:
    content: sinh(x, name='')
    parameters:
    - description: 'numpy array or any @cntk.ops.functions.Function that outputs a
        tensor

        '
      id: x
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.sinh
- example:
  - "\n```\n\n>>> # slice using input variable\n>>> # create 2x3 matrix\n>>> x1 =\
    \ C.input_variable((2,3))\n>>> # slice index 1 (second) at first axis\n>>> C.slice(x1,\
    \ 0, 1, 2).eval({x1: np.asarray([[[1,2,-3],\n...                             \
    \                [4, 5, 6]]],dtype=np.float32)})\narray([[[ 4.,  5.,  6.]]], dtype=float32)\n\
    <BLANKLINE>\n>>> # slice index 0 (first) at second axis\n>>> C.slice(x1, 1, 0,\
    \ 1).eval({x1: np.asarray([[[1,2,-3],\n...                                   \
    \          [4, 5, 6]]],dtype=np.float32)})\narray([[[ 1.],\n        [ 4.]]], dtype=float32)\n\
    >>> # slice with strides\n>>> C.slice(x1, 0, 0, 2, 2).eval({x1: np.asarray([[[1,2,-3],\n\
    ...                                                [4, 5, 6]]],dtype=np.float32)})\n\
    array([[[ 1.,  2., -3.]]], dtype=float32)\n<BLANKLINE>\n>>> # reverse\n>>> C.slice(x1,\
    \ 0, 0, 2, -1).eval({x1: np.asarray([[[1,2,-3],\n...                         \
    \                        [4, 5, 6]]],dtype=np.float32)})\narray([[[ 4.,  5., \
    \ 6.],\n[ 1.,  2., -3.]]], dtype=float32)\n<BLANKLINE>\n>>> # slice along multiple\
    \ axes\n>>> C.slice(x1, [0,1], [1,0], [2,1]).eval({x1: np.asarray([[[1, 2, -3],\n\
    ...                                                         [4, 5, 6]]],dtype=np.float32)})\n\
    array([[[ 4.]]], dtype=float32)\n<BLANKLINE>\n>>> # slice using constant\n>>>\
    \ data = np.asarray([[1, 2, -3],\n...                    [4, 5,  6]], dtype=np.float32)\n\
    >>> x = C.constant(value=data)\n>>> C.slice(x, 0, 1, 2).eval()\narray([[ 4., \
    \ 5.,  6.]], dtype=float32)\n>>> C.slice(x, 1, 0, 1).eval()\narray([[ 1.],\n \
    \      [ 4.]], dtype=float32)\n>>> C.slice(x, [0,1], [1,0], [2,1]).eval()\narray([[\
    \ 4.]], dtype=float32)\n<BLANKLINE>\n>>> # slice using the index overload\n>>>\
    \ data = np.asarray([[1, 2, -3],\n...                    [4, 5,  6]], dtype=np.float32)\n\
    >>> x = C.constant(value=data)\n>>> x[0].eval()\narray([[ 1.,  2.,  -3.]], dtype=float32)\n\
    >>> x[0, [1,2]].eval()\narray([[ 2.,  -3.]], dtype=float32)\n<BLANKLINE>\n>>>\
    \ x[1].eval()\narray([[ 4.,  5.,  6.]], dtype=float32)\n>>> x[:,:2,:].eval()\n\
    array([[ 1.,  2.],\n       [ 4.,  5.]], dtype=float32)\n```\n"
  fullName: cntk.ops.slice
  langs:
  - python
  module: cntk.ops
  name: slice
  seealsoContent: "See also: Indexing in NumPy: [https://docs.scipy.org/doc/numpy/reference/arrays.indexing.html](https://docs.scipy.org/doc/numpy/reference/arrays.indexing.html)\
    \ \n"
  source:
    id: slice
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 1953
  summary: 'Slice the input along one or multiple axes.

    '
  syntax:
    content: slice(x, axis, begin_index, end_index, strides=None, name='')
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.slice
- example:
  - "\n```\n\n>>> C.softmax([[1, 1, 2, 3]]).eval()\narray([[ 0.082595,  0.082595,\
    \  0.224515,  0.610296]], dtype=float32)\n```\n\n\n```\n\n>>> C.softmax([1, 1]).eval()\n\
    array([ 0.5,  0.5], dtype=float32)\n```\n\n\n```\n\n>>> C.softmax([[[1, 1], [3,\
    \ 5]]], axis=-1).eval()\narray([[[ 0.5     ,  0.5     ],\n        [ 0.119203,\
    \  0.880797]]], dtype=float32)\n```\n\n\n```\n\n>>> C.softmax([[[1, 1], [3, 5]]],\
    \ axis=1).eval()\narray([[[ 0.119203,  0.017986],\n        [ 0.880797,  0.982014]]],\
    \ dtype=float32)\n```\n"
  fullName: cntk.ops.softmax
  langs:
  - python
  module: cntk.ops
  name: softmax
  source:
    id: softmax
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 1524
  summary: 'Computes the gradient of  at `z = x`. Concretely,



    with the understanding that the implementation can use equivalent formulas

    for efficiency and numerical stability.


    The output is a vector of non-negative numbers that sum to 1 and can

    therefore be interpreted as probabilities for mutually exclusive outcomes

    as in the case of multiclass classification.


    If `axis` is given as integer, then the softmax will be computed along that axis.

    If the provided `axis` is -1, it will be computed along the last axis. Otherwise,

    softmax will be applied to all axes.

    '
  syntax:
    content: softmax(x, axis=None, name='')
    parameters:
    - description: 'numpy array or any @cntk.ops.functions.Function that outputs a
        tensor

        '
      id: x
    - description: 'axis along which the softmax operation will be performed

        '
      id: axis
      type:
      - 'int or @cntk.axis.Axis

        '
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.softmax
- example:
  - '

    ```


    >>> C.softplus([[-1, -0.5, 0, 1, 2]]).eval()

    array([[ 0.313262,  0.474077,  0.693147,  1.313262,  2.126928]], dtype=float32)

    ```



    ```


    >>> C.softplus([[-1, -0.5, 0, 1, 2]], steepness=4).eval()

    array([[ 0.004537,  0.031732,  0.173287,  1.004537,  2.000084]], dtype=float32)

    ```

    '
  fullName: cntk.ops.softplus
  langs:
  - python
  module: cntk.ops
  name: softplus
  source:
    id: softplus
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 1352
  summary: 'Softplus operation. Computes the element-wise softplus of `x`:



    The optional `steepness` allows to make the knee sharper (`steepness>1`) or softer,
    by computing

    `softplus(x * steepness) / steepness`.

    (For very large steepness, this approaches a linear rectifier).


    The output tensor has the same shape as `x`.

    '
  syntax:
    content: softplus(x, steepness=1, name='')
    parameters:
    - description: 'any @cntk.ops.functions.Function that outputs a tensor.

        '
      id: x
      type:
      - 'numpy.array or @cntk.ops.functions.Function

        '
    - description: 'optional steepness factor

        '
      id: steepness
      type:
      - float, optional
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, default to ''
    return:
      description: 'An instance of @cntk.ops.functions.Function

        '
      type:
      - cntk.ops.functions.Function
  type: function
  uid: cntk.ops.softplus
- example:
  - "\n```\n\n>>> # create 2x2 matrix in a sequence of length 1 in a batch of one\
    \ sample\n>>> data1 = np.asarray([[[1, 2],\n...                      [4, 5]]],\
    \ dtype=np.float32)\n```\n\n\n```\n\n>>> x = C.constant(value=data1)\n>>> # create\
    \ 3x2 matrix in a sequence of length 1 in a batch of one sample\n>>> data2 = np.asarray([[[10,\
    \ 20],\n...                       [30, 40],\n...                       [50, 60]]],dtype=np.float32)\n\
    >>> y = C.constant(value=data2)\n>>> # splice both inputs on axis=0 returns a\
    \ 5x2 matrix\n>>> C.splice(x, y, axis=1).eval()\narray([[[  1.,   2.],\n     \
    \   [  4.,   5.],\n        [ 10.,  20.],\n        [ 30.,  40.],\n        [ 50.,\
    \  60.]]], dtype=float32)\n```\n"
  fullName: cntk.ops.splice
  langs:
  - python
  module: cntk.ops
  name: splice
  source:
    id: splice
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 2044
  summary: 'Concatenate the input tensors along an axis.

    '
  syntax:
    content: splice(*inputs, **kw_axis_name)
    parameters:
    - description: 'one or more input tensors

        '
      id: inputs
    - description: 'axis along which the

        concatenation will be performed

        '
      id: axis
      type:
      - 'int or @cntk.axis.Axis

        , optional, keyword only'
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional, keyword only
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.splice
- example:
  - '

    ```


    >>> C.sqrt([0., 4.]).eval()

    array([ 0.,  2.], dtype=float32)

    ```

    '
  fullName: cntk.ops.sqrt
  langs:
  - python
  module: cntk.ops
  name: sqrt
  source:
    id: sqrt
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 1644
  summary: "Computes the element-wise square-root of `x`:\n\n\nNote: CNTK returns\
    \ zero for sqrt of negative nubmers, this will be changed to return NaN \n"
  syntax:
    content: sqrt(x, name='')
    parameters:
    - description: 'numpy array or any @cntk.ops.functions.Function that outputs a
        tensor

        '
      id: x
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.sqrt
- example:
  - '

    ```


    >>> C.square([1., 10.]).eval()

    array([   1.,  100.], dtype=float32)

    ```

    '
  fullName: cntk.ops.square
  langs:
  - python
  module: cntk.ops
  name: square
  source:
    id: square
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 1670
  summary: 'Computes the element-wise square of `x`:

    '
  syntax:
    content: square(x, name='')
    parameters:
    - description: 'numpy array or any @cntk.ops.functions.Function that outputs a
        tensor

        '
      id: x
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.square
- fullName: cntk.ops.stop_gradient
  langs:
  - python
  module: cntk.ops
  name: stop_gradient
  source:
    id: stop_gradient
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 2978
  summary: 'Outputs its input as it is and prevents any gradient contribution from
    its output to its input.

    '
  syntax:
    content: stop_gradient(input, name='')
    parameters:
    - description: 'class:*~cntk.ops.functions.Function* that outputs a tensor

        '
      id: input
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.stop_gradient
- example:
  - "\n```\n\n>>> C.swapaxes([[[0,1],[2,3],[4,5]]], 1, 2).eval()\narray([[[ 0.,  2.,\
    \  4.],\n        [ 1.,  3.,  5.]]], dtype=float32)\n```\n"
  fullName: cntk.ops.swapaxes
  langs:
  - python
  module: cntk.ops
  name: swapaxes
  source:
    id: swapaxes
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 1928
  summary: 'Swaps two axes of the tensor. The output tensor has the same data but
    with

    `axis1` and `axis2` swapped.

    '
  syntax:
    content: swapaxes(x, axis1=0, axis2=1, name='')
    parameters:
    - description: 'tensor to be transposed

        '
      id: x
    - description: 'the axis to swap with `axis2`

        '
      id: axis1
      type:
      - 'int or @cntk.axis.Axis

        '
    - description: 'the axis to swap with `axis1`

        '
      id: axis2
      type:
      - 'int or @cntk.axis.Axis

        '
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.swapaxes
- example:
  - "\n```\n\n>>> C.tanh([[1,2],[3,4]]).eval()\narray([[ 0.761594,  0.964028],\n \
    \      [ 0.995055,  0.999329]], dtype=float32)\n```\n"
  fullName: cntk.ops.tanh
  langs:
  - python
  module: cntk.ops
  name: tanh
  source:
    id: tanh
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 1413
  summary: 'Computes the element-wise tanh of `x`:


    The output tensor has the same shape as `x`.

    '
  syntax:
    content: tanh(x, name='')
    parameters:
    - description: 'numpy array or any @cntk.ops.functions.Function that outputs a
        tensor

        '
      id: x
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.tanh
- example:
  - "\n```\n\n>>> C.times([[1,2],[3,4]], [[5],[6]]).eval()\narray([[ 17.],\n     \
    \  [ 39.]], dtype=float32)\n```\n\n\n```\n\n>>> C.times(1.*np.reshape(np.arange(8),\
    \ (2,2,2)),1.*np.reshape(np.arange(8), (2,2,2)), output_rank=1).eval()\narray([[\
    \ 28.,  34.],\n       [ 76.,  98.]])\n```\n\n\n```\n\n>>> C.times(1.*np.reshape(np.arange(8),\
    \ (2,2,2)),1.*np.reshape(np.arange(8), (2,2,2)), output_rank=2).eval()\narray([[[[\
    \  4.,   5.],\n         [  6.,   7.]],\n<BLANKLINE>\n        [[ 12.,  17.],\n\
    \         [ 22.,  27.]]],\n<BLANKLINE>\n<BLANKLINE>\n       [[[ 20.,  29.],\n\
    \         [ 38.,  47.]],\n<BLANKLINE>\n        [[ 28.,  41.],\n         [ 54.,\
    \  67.]]]])\n```\n"
  fullName: cntk.ops.times
  langs:
  - python
  module: cntk.ops
  name: times
  source:
    id: times
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 940
  summary: "The output of this operation is the matrix product of the two input matrices.\n\
    It supports broadcasting. Sparse is supported in the left operand, if it is a\
    \ matrix.\nThe operator '@' has been overloaded such that in Python 3.5 and later\
    \ X @ W equals times(X, W).\n\nFor better performance on times operation on sequence\
    \ which is followed by sequence.reduce_sum, use\ninfer_input_rank_to_map=TIMES_REDUCE_SEQUENCE_AXIS_WITHOUT_INFERRED_INPUT_RANK,\
    \ i.e. replace following:\n\n<!-- literal_block {\"backrefs\": [], \"ids\": [],\
    \ \"names\": [], \"classes\": [], \"xml:space\": \"preserve\", \"dupnames\": []}\
    \ -->\n\n````\n\n   sequence.reduce_sum(times(seq1, seq2))\n   ````\n\nwith:\n\
    \n<!-- literal_block {\"backrefs\": [], \"ids\": [], \"names\": [], \"classes\"\
    : [], \"xml:space\": \"preserve\", \"dupnames\": []} -->\n\n````\n\n   times(seq1,\
    \ seq2, infer_input_rank_to_map=TIMES_REDUCE_SEQUENCE_AXIS_WITHOUT_INFERRED_INPUT_RANK)\n\
    \   ````\n"
  syntax:
    content: times(left, right, output_rank=1, infer_input_rank_to_map=-1, name='')
    parameters:
    - description: 'left side matrix or tensor

        '
      id: left
    - description: 'right side matrix or tensor

        '
      id: right
    - description: 'in case we have tensors as arguments, output_rank represents

        the number of axes to be collapsed in order to transform the tensors

        into matrices, perform the operation and then reshape back (explode the axes)

        '
      id: output_rank
      type:
      - int
    - description: 'meant for internal use only. Always use default value

        '
      id: infer_input_rank_to_map
      type:
      - int
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.times
- example:
  - "\n```\n\n>>> a=np.array([[1,2],[3,4]],dtype=np.float32)\n>>> b=np.array([2,-1],dtype=np.float32)\n\
    >>> c=np.array([[2,-1]],dtype=np.float32)\n>>> d=np.reshape(np.arange(24,dtype=np.float32),(4,3,2))\n\
    >>> print(C.times_transpose(a, a).eval())\n[[  5.  11.]\n [ 11.  25.]]\n>>> print(C.times_transpose(a,\
    \ b).eval())\n[[ 0.]\n [ 2.]]\n>>> print(C.times_transpose(a, c).eval())\n[[ 0.]\n\
    \ [ 2.]]\n>>> print(C.times_transpose(b, a).eval())\n[ 0.  2.]\n>>> print(C.times_transpose(b,\
    \ b).eval())\n[ 5.]\n>>> print(C.times_transpose(b, c).eval())\n[ 5.]\n>>> print(C.times_transpose(c,\
    \ a).eval())\n[[ 0.  2.]]\n>>> print(C.times_transpose(c, b).eval())\n[[ 5.]]\n\
    >>> print(C.times_transpose(c, c).eval())\n[[ 5.]]\n>>> print(C.times_transpose(d,\
    \ a).eval())\n[[[   2.    4.]\n  [   8.   18.]\n  [  14.   32.]]\n<BLANKLINE>\n\
    \ [[  20.   46.]\n  [  26.   60.]\n  [  32.   74.]]\n<BLANKLINE>\n [[  38.   88.]\n\
    \  [  44.  102.]\n  [  50.  116.]]\n<BLANKLINE>\n [[  56.  130.]\n  [  62.  144.]\n\
    \  [  68.  158.]]]\n>>> print(C.times_transpose(d, b).eval())\n[[[ -1.]\n  [ \
    \ 1.]\n  [  3.]]\n<BLANKLINE>\n [[  5.]\n  [  7.]\n  [  9.]]\n<BLANKLINE>\n [[\
    \ 11.]\n  [ 13.]\n  [ 15.]]\n<BLANKLINE>\n [[ 17.]\n  [ 19.]\n  [ 21.]]]\n>>>\
    \ print(C.times_transpose(d, c).eval())\n[[[ -1.]\n  [  1.]\n  [  3.]]\n<BLANKLINE>\n\
    \ [[  5.]\n  [  7.]\n  [  9.]]\n<BLANKLINE>\n [[ 11.]\n  [ 13.]\n  [ 15.]]\n<BLANKLINE>\n\
    \ [[ 17.]\n  [ 19.]\n  [ 21.]]]\n```\n"
  fullName: cntk.ops.times_transpose
  langs:
  - python
  module: cntk.ops
  name: times_transpose
  source:
    id: times_transpose
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 998
  summary: 'The output of this operation is the product of the first (`left`) argument
    with the second (`right`) argument transposed.

    The second (`right`) argument must have a rank of 1 or 2.

    This operation is conceptually computing `np.dot(left, right.T)` except when `right`
    is a vector

    in which case the output is `np.dot(left,np.reshape(right,(1,-1)).T)` (matching
    numpy when `left` is a vector).

    '
  syntax:
    content: times_transpose(left, right, name='')
    parameters:
    - description: 'left side tensor

        '
      id: left
    - description: 'right side matrix or vector

        '
      id: right
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.times_transpose
- example:
  - '

    ```


    >>> data = np.arange(12).reshape((3,2,2))

    >>> x = C.constant(value=data)

    >>> y = C.to_batch(x)

    >>> y.shape

    (2, 2)

    ```

    '
  fullName: cntk.ops.to_batch
  langs:
  - python
  module: cntk.ops
  name: to_batch
  source:
    id: to_batch
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 2119
  summary: 'Concatenate the input tensor''s first axis to batch axis.

    '
  syntax:
    content: to_batch(x, name='')
    parameters:
    - description: 'a tensor with dynamic axis

        '
      id: x
    - description: '(str, optional, keyword only): the name of the Function instance
        in the network

        '
      id: name
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.to_batch
- fullName: cntk.ops.to_sequence
  langs:
  - python
  module: cntk.ops
  name: to_sequence
  source:
    id: to_sequence
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 2548
  summary: 'This function converts ''x'' to a sequence using the most significant

    static axis [0] as the sequence axis.


    The sequenceLengths input is optional; if unspecified, all sequences are

    assumed to be of the same length; i.e. dimensionality of the most significant

    static axis



    '
  syntax:
    content: to_sequence(x, sequence_lengths=None, sequence_axis_name_prefix='toSequence_',
      name='')
    parameters:
    - description: 'the tensor (or its name) which is converted to a sequence

        '
      id: x
    - description: 'Optional tensor operand representing the sequence lengths.

        if unspecified, all sequences are assumed to be of the same length;

        i.e. dimensionality of the most significant static axis.

        '
      id: sequence_lengths
    - description: 'prefix of the new sequence axis name.

        '
      id: sequence_axis_name_prefix
      type:
      - str, optional
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.to_sequence
- fullName: cntk.ops.to_sequence_like
  langs:
  - python
  module: cntk.ops
  name: to_sequence_like
  source:
    id: to_sequence_like
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 2583
  summary: 'This function converts ''x'' to a sequence using the most significant

    static axis [0] as the sequence axis. The length of the sequences are

    obtained from the ''dynamic_axes_like'' operand.



    '
  syntax:
    content: to_sequence_like(x, dynamic_axes_like, name='')
    parameters:
    - description: 'the tensor (or its name) which is converted to a sequence

        '
      id: x
    - description: 'Tensor operand used to obtain the lengths of

        the generated sequences. The dynamic axes of the generated sequence

        tensor match the dynamic axes of the ''dynamic_axes_like'' operand.

        '
      id: dynamic_axes_like
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.to_sequence_like
- example:
  - '

    ```


    >>> a = np.arange(24).reshape(2,3,4).astype(''f'')

    >>> np.array_equal(C.transpose(a, perm=(2, 0, 1)).eval(), np.transpose(a, (2,
    0, 1)))

    True

    ```

    '
  fullName: cntk.ops.transpose
  langs:
  - python
  module: cntk.ops
  name: transpose
  source:
    id: transpose
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 1902
  summary: 'Permutes the axes of the tensor. The output has the same data but the
    axes

    are permuted according to `perm`.

    '
  syntax:
    content: transpose(x, perm, name='')
    parameters:
    - description: 'tensor to be transposed

        '
      id: x
    - description: 'the permutation to apply to the axes.

        '
      id: perm
      type:
      - list
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.transpose
- example:
  - "\n```\n\n>>> data = np.arange(12).reshape((3,2,2))\n>>> x = C.input((2,2))\n\
    >>> C.unpack_batch(x).eval({x:data})\narray([[[  0.,   1.],\n        [  2.,  \
    \ 3.]],\n<BLANKLINE>\n       [[  4.,   5.],\n        [  6.,   7.]],\n<BLANKLINE>\n\
    \       [[  8.,   9.],\n        [ 10.,  11.]]], dtype=float32)\n```\n"
  fullName: cntk.ops.unpack_batch
  langs:
  - python
  module: cntk.ops
  name: unpack_batch
  source:
    id: unpack_batch
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 2089
  summary: 'Concatenate the input tensor''s last dynamic axis to static axis.

    Only tensors with batch axis are supported now.

    '
  syntax:
    content: unpack_batch(x, name='')
    parameters:
    - description: 'a tensor with dynamic axis

        '
      id: x
    - description: '(str, optional, keyword only): the name of the Function instance
        in the network

        '
      id: name
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.unpack_batch
- example:
  - "\n```\n\n>>> img = np.reshape(np.arange(16, dtype = np.float32), [1, 4, 4])\n\
    >>> x = C.input_variable(img.shape)\n>>> y = C.pooling(x, C.MAX_POOLING, (2,2),\
    \ (2,2))\n>>> C.unpooling(y, x, C.MAX_UNPOOLING, (2,2), (2,2)).eval({x : [img]})\n\
    array([[[[  0.,   0.,   0.,   0.],\n          [  0.,   5.,   0.,   7.],\n    \
    \      [  0.,   0.,   0.,   0.],\n          [  0.,  13.,   0.,  15.]]]], dtype=float32)\n\
    ```\n"
  fullName: cntk.ops.unpooling
  langs:
  - python
  module: cntk.ops
  name: unpooling
  source:
    id: unpooling
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.1
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 422
  summary: 'Unpools the `operand` using information from `pooling_input`. Unpooling
    mirrors the operations

    performed by pooling and depends on the values provided to the corresponding pooling
    operation. The output

    should have the same shape as pooling_input. Pooling the result of an unpooling
    operation should

    give back the original input.

    '
  syntax:
    content: unpooling(operand, pooling_input, unpooling_type, unpooling_window_shape,
      strides=(1,), auto_padding=[False], name='')
    parameters:
    - description: 'unpooling input

        '
      id: operand
    - description: 'input to the corresponding pooling operation

        '
      id: pooling_input
    - description: 'only @cntk.ops.MAX_UNPOOLING is supported now

        '
      id: unpooling_type
    - description: 'dimensions of the unpooling window

        '
      id: unpooling_window_shape
    - description: 'strides.

        '
      id: strides
      type:
      - default 1
    - description: 'automatic padding flags for each input dimension.

        '
      id: auto_padding
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.unpooling
references:
- fullName: cntk.ops.abs
  isExternal: false
  name: abs
  parent: cntk.ops
  uid: cntk.ops.abs
- fullName: cntk.ops.alias
  isExternal: false
  name: alias
  parent: cntk.ops
  uid: cntk.ops.alias
- fullName: cntk.ops.argmax
  isExternal: false
  name: argmax
  parent: cntk.ops
  uid: cntk.ops.argmax
- fullName: cntk.ops.argmin
  isExternal: false
  name: argmin
  parent: cntk.ops
  uid: cntk.ops.argmin
- fullName: cntk.ops.as_block
  isExternal: false
  name: as_block
  parent: cntk.ops
  uid: cntk.ops.as_block
- fullName: cntk.ops.as_composite
  isExternal: false
  name: as_composite
  parent: cntk.ops
  uid: cntk.ops.as_composite
- fullName: cntk.ops.assign
  isExternal: false
  name: assign
  parent: cntk.ops
  uid: cntk.ops.assign
- fullName: cntk.ops.associative_multi_arg
  isExternal: false
  name: associative_multi_arg
  parent: cntk.ops
  uid: cntk.ops.associative_multi_arg
- fullName: cntk.ops.batch_normalization
  isExternal: false
  name: batch_normalization
  parent: cntk.ops
  uid: cntk.ops.batch_normalization
- fullName: cntk.ops.ceil
  isExternal: false
  name: ceil
  parent: cntk.ops
  uid: cntk.ops.ceil
- fullName: cntk.ops.clip
  isExternal: false
  name: clip
  parent: cntk.ops
  uid: cntk.ops.clip
- fullName: cntk.ops.combine
  isExternal: false
  name: combine
  parent: cntk.ops
  uid: cntk.ops.combine
- fullName: cntk.ops.constant
  isExternal: false
  name: constant
  parent: cntk.ops
  uid: cntk.ops.constant
- fullName: cntk.ops.convolution
  isExternal: false
  name: convolution
  parent: cntk.ops
  uid: cntk.ops.convolution
- fullName: cntk.ops.convolution_transpose
  isExternal: false
  name: convolution_transpose
  parent: cntk.ops
  uid: cntk.ops.convolution_transpose
- fullName: cntk.ops.cos
  isExternal: false
  name: cos
  parent: cntk.ops
  uid: cntk.ops.cos
- fullName: cntk.ops.cosh
  isExternal: false
  name: cosh
  parent: cntk.ops
  uid: cntk.ops.cosh
- fullName: cntk.ops.dropout
  isExternal: false
  name: dropout
  parent: cntk.ops
  uid: cntk.ops.dropout
- fullName: cntk.ops.element_divide
  isExternal: false
  name: element_divide
  parent: cntk.ops
  uid: cntk.ops.element_divide
- fullName: cntk.ops.element_max
  isExternal: false
  name: element_max
  parent: cntk.ops
  uid: cntk.ops.element_max
- fullName: cntk.ops.element_min
  isExternal: false
  name: element_min
  parent: cntk.ops
  uid: cntk.ops.element_min
- fullName: cntk.ops.element_select
  isExternal: false
  name: element_select
  parent: cntk.ops
  uid: cntk.ops.element_select
- fullName: cntk.ops.element_times
  isExternal: false
  name: element_times
  parent: cntk.ops
  uid: cntk.ops.element_times
- fullName: cntk.ops.elu
  isExternal: false
  name: elu
  parent: cntk.ops
  uid: cntk.ops.elu
- fullName: cntk.ops.equal
  isExternal: false
  name: equal
  parent: cntk.ops
  uid: cntk.ops.equal
- fullName: cntk.ops.exp
  isExternal: false
  name: exp
  parent: cntk.ops
  uid: cntk.ops.exp
- fullName: cntk.ops.floor
  isExternal: false
  name: floor
  parent: cntk.ops
  uid: cntk.ops.floor
- fullName: cntk.ops.forward_backward
  isExternal: false
  name: forward_backward
  parent: cntk.ops
  uid: cntk.ops.forward_backward
- fullName: cntk.ops.gather
  isExternal: false
  name: gather
  parent: cntk.ops
  uid: cntk.ops.gather
- fullName: cntk.ops.greater
  isExternal: false
  name: greater
  parent: cntk.ops
  uid: cntk.ops.greater
- fullName: cntk.ops.greater_equal
  isExternal: false
  name: greater_equal
  parent: cntk.ops
  uid: cntk.ops.greater_equal
- fullName: cntk.ops.hardmax
  isExternal: false
  name: hardmax
  parent: cntk.ops
  uid: cntk.ops.hardmax
- fullName: cntk.ops.input
  isExternal: false
  name: input
  parent: cntk.ops
  uid: cntk.ops.input
- fullName: cntk.ops.input_variable
  isExternal: false
  name: input_variable
  parent: cntk.ops
  uid: cntk.ops.input_variable
- fullName: cntk.ops.labels_to_graph
  isExternal: false
  name: labels_to_graph
  parent: cntk.ops
  uid: cntk.ops.labels_to_graph
- fullName: cntk.ops.leaky_relu
  isExternal: false
  name: leaky_relu
  parent: cntk.ops
  uid: cntk.ops.leaky_relu
- fullName: cntk.ops.less
  isExternal: false
  name: less
  parent: cntk.ops
  uid: cntk.ops.less
- fullName: cntk.ops.less_equal
  isExternal: false
  name: less_equal
  parent: cntk.ops
  uid: cntk.ops.less_equal
- fullName: cntk.ops.log
  isExternal: false
  name: log
  parent: cntk.ops
  uid: cntk.ops.log
- fullName: cntk.ops.log_add_exp
  isExternal: false
  name: log_add_exp
  parent: cntk.ops
  uid: cntk.ops.log_add_exp
- fullName: cntk.ops.minus
  isExternal: false
  name: minus
  parent: cntk.ops
  uid: cntk.ops.minus
- fullName: cntk.ops.negate
  isExternal: false
  name: negate
  parent: cntk.ops
  uid: cntk.ops.negate
- fullName: cntk.ops.not_equal
  isExternal: false
  name: not_equal
  parent: cntk.ops
  uid: cntk.ops.not_equal
- fullName: cntk.ops.one_hot
  isExternal: false
  name: one_hot
  parent: cntk.ops
  uid: cntk.ops.one_hot
- fullName: cntk.ops.optimized_rnnstack
  isExternal: false
  name: optimized_rnnstack
  parent: cntk.ops
  uid: cntk.ops.optimized_rnnstack
- fullName: cntk.ops.output_variable
  isExternal: false
  name: output_variable
  parent: cntk.ops
  uid: cntk.ops.output_variable
- fullName: cntk.ops.param_relu
  isExternal: false
  name: param_relu
  parent: cntk.ops
  uid: cntk.ops.param_relu
- fullName: cntk.ops.parameter
  isExternal: false
  name: parameter
  parent: cntk.ops
  uid: cntk.ops.parameter
- fullName: cntk.ops.per_dim_mean_variance_normalize
  isExternal: false
  name: per_dim_mean_variance_normalize
  parent: cntk.ops
  uid: cntk.ops.per_dim_mean_variance_normalize
- fullName: cntk.ops.placeholder
  isExternal: false
  name: placeholder
  parent: cntk.ops
  uid: cntk.ops.placeholder
- fullName: cntk.ops.plus
  isExternal: false
  name: plus
  parent: cntk.ops
  uid: cntk.ops.plus
- fullName: cntk.ops.pooling
  isExternal: false
  name: pooling
  parent: cntk.ops
  uid: cntk.ops.pooling
- fullName: cntk.ops.pow
  isExternal: false
  name: pow
  parent: cntk.ops
  uid: cntk.ops.pow
- fullName: cntk.ops.random_sample
  isExternal: false
  name: random_sample
  parent: cntk.ops
  uid: cntk.ops.random_sample
- fullName: cntk.ops.random_sample_inclusion_frequency
  isExternal: false
  name: random_sample_inclusion_frequency
  parent: cntk.ops
  uid: cntk.ops.random_sample_inclusion_frequency
- fullName: cntk.ops.reciprocal
  isExternal: false
  name: reciprocal
  parent: cntk.ops
  uid: cntk.ops.reciprocal
- fullName: cntk.ops.reconcile_dynamic_axes
  isExternal: false
  name: reconcile_dynamic_axes
  parent: cntk.ops
  uid: cntk.ops.reconcile_dynamic_axes
- fullName: cntk.ops.reduce_log_sum_exp
  isExternal: false
  name: reduce_log_sum_exp
  parent: cntk.ops
  uid: cntk.ops.reduce_log_sum_exp
- fullName: cntk.ops.reduce_max
  isExternal: false
  name: reduce_max
  parent: cntk.ops
  uid: cntk.ops.reduce_max
- fullName: cntk.ops.reduce_mean
  isExternal: false
  name: reduce_mean
  parent: cntk.ops
  uid: cntk.ops.reduce_mean
- fullName: cntk.ops.reduce_min
  isExternal: false
  name: reduce_min
  parent: cntk.ops
  uid: cntk.ops.reduce_min
- fullName: cntk.ops.reduce_prod
  isExternal: false
  name: reduce_prod
  parent: cntk.ops
  uid: cntk.ops.reduce_prod
- fullName: cntk.ops.reduce_sum
  isExternal: false
  name: reduce_sum
  parent: cntk.ops
  uid: cntk.ops.reduce_sum
- fullName: cntk.ops.relu
  isExternal: false
  name: relu
  parent: cntk.ops
  uid: cntk.ops.relu
- fullName: cntk.ops.reshape
  isExternal: false
  name: reshape
  parent: cntk.ops
  uid: cntk.ops.reshape
- fullName: cntk.ops.roipooling
  isExternal: false
  name: roipooling
  parent: cntk.ops
  uid: cntk.ops.roipooling
- fullName: cntk.ops.round
  isExternal: false
  name: round
  parent: cntk.ops
  uid: cntk.ops.round
- fullName: cntk.ops.selu
  isExternal: false
  name: selu
  parent: cntk.ops
  uid: cntk.ops.selu
- fullName: cntk.ops.sigmoid
  isExternal: false
  name: sigmoid
  parent: cntk.ops
  uid: cntk.ops.sigmoid
- fullName: cntk.ops.sin
  isExternal: false
  name: sin
  parent: cntk.ops
  uid: cntk.ops.sin
- fullName: cntk.ops.sinh
  isExternal: false
  name: sinh
  parent: cntk.ops
  uid: cntk.ops.sinh
- fullName: cntk.ops.slice
  isExternal: false
  name: slice
  parent: cntk.ops
  uid: cntk.ops.slice
- fullName: cntk.ops.softmax
  isExternal: false
  name: softmax
  parent: cntk.ops
  uid: cntk.ops.softmax
- fullName: cntk.ops.softplus
  isExternal: false
  name: softplus
  parent: cntk.ops
  uid: cntk.ops.softplus
- fullName: cntk.ops.splice
  isExternal: false
  name: splice
  parent: cntk.ops
  uid: cntk.ops.splice
- fullName: cntk.ops.sqrt
  isExternal: false
  name: sqrt
  parent: cntk.ops
  uid: cntk.ops.sqrt
- fullName: cntk.ops.square
  isExternal: false
  name: square
  parent: cntk.ops
  uid: cntk.ops.square
- fullName: cntk.ops.stop_gradient
  isExternal: false
  name: stop_gradient
  parent: cntk.ops
  uid: cntk.ops.stop_gradient
- fullName: cntk.ops.swapaxes
  isExternal: false
  name: swapaxes
  parent: cntk.ops
  uid: cntk.ops.swapaxes
- fullName: cntk.ops.tanh
  isExternal: false
  name: tanh
  parent: cntk.ops
  uid: cntk.ops.tanh
- fullName: cntk.ops.times
  isExternal: false
  name: times
  parent: cntk.ops
  uid: cntk.ops.times
- fullName: cntk.ops.times_transpose
  isExternal: false
  name: times_transpose
  parent: cntk.ops
  uid: cntk.ops.times_transpose
- fullName: cntk.ops.to_batch
  isExternal: false
  name: to_batch
  parent: cntk.ops
  uid: cntk.ops.to_batch
- fullName: cntk.ops.to_sequence
  isExternal: false
  name: to_sequence
  parent: cntk.ops
  uid: cntk.ops.to_sequence
- fullName: cntk.ops.to_sequence_like
  isExternal: false
  name: to_sequence_like
  parent: cntk.ops
  uid: cntk.ops.to_sequence_like
- fullName: cntk.ops.transpose
  isExternal: false
  name: transpose
  parent: cntk.ops
  uid: cntk.ops.transpose
- fullName: cntk.ops.unpack_batch
  isExternal: false
  name: unpack_batch
  parent: cntk.ops
  uid: cntk.ops.unpack_batch
- fullName: cntk.ops.unpooling
  isExternal: false
  name: unpooling
  parent: cntk.ops
  uid: cntk.ops.unpooling
- fullName: cntk.ops.functions
  isExternal: false
  name: functions
  parent: cntk.ops
  uid: cntk.ops.functions
- fullName: cntk.ops.sequence
  isExternal: false
  name: sequence
  parent: cntk.ops
  uid: cntk.ops.sequence
